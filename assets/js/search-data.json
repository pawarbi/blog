{
  
    
        "post0": {
            "title": "",
            "content": "Project Goals . This is a quarterly sales data of a French retail company from Prof. Rob Hyndman&#39;s &quot;Forecasting Methods &amp; Applications&quot; book. I have uploaded the data to my github. I chose this example because it&#39;s deceptively simple, easy to explain/demonstrate key concepts and Prof. Hyndman later applied the state space approach to this series using family of ETS models. The goals for this project are: . Forecast 1 year ahead , i.e next 4 quarters | Create a forecast pipeline using Python first &amp; later R for comparison purposes | Compare various forecasting methods &amp; choose the best model. Evaluate the models using various evaluation criteria. | Focus on explanability and identify how EDA informs the model selection | Dcoument my findings &amp; notes to self | Importing libraries . #Author: Sandeep Pawar #Version: 1.0 #Date Mar 27, 2020 import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import scipy from scipy.stats import anderson from statsmodels.tools.eval_measures import rmse from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot from statsmodels.tsa.seasonal import seasonal_decompose from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing from statsmodels.stats.diagnostic import acorr_ljungbox as ljung #from nimbusml.timeseries import SsaForecaster from statsmodels.tsa.statespace.tools import diff as diff import statsmodels.api as sm import altair as alt import itertools #import gluonts import pmdarima as pm from pmdarima import ARIMA, auto_arima from scipy import signal from scipy.stats import shapiro from scipy.stats import boxcox %matplotlib inline import warnings warnings.filterwarnings(&quot;ignore&quot;) import rpy2 from rpy2.robjects import pandas2ri pandas2ri.activate() %load_ext rpy2.ipython . The rpy2.ipython extension is already loaded. To reload it, use: %reload_ext rpy2.ipython . I have found that results could be significanlty different if you use different version of the libraries, especially with statsmodels &amp; rpy2. So if you want to reproduce these results, be sure to use the same versions of these libraries. For this project, I created a conda virtual environment as rpy2 requires specific versions of Pandas &amp; certain R libraries . #Printing library versions print(&#39;Pandas:&#39;, pd.__version__) print(&#39;Statsmodels:&#39;, sm.__version__) print(&#39;Scipy:&#39;, scipy.__version__) print(&#39;Rpy2:&#39;, rpy2.__version__) . Pandas: 0.25.0 Statsmodels: 0.11.0 Scipy: 1.4.1 Rpy2: 2.9.4 . # Define some custom functions to help the analysis def MAPE(y_true, y_pred): &quot;&quot;&quot; %Error compares true value with predicted value. Lower the better. Use this along with rmse(). If the series has outliers, compare/select model using MAPE instead of rmse() &quot;&quot;&quot; y_true, y_pred = np.array(y_true), np.array(y_pred) return np.mean(np.abs((y_true - y_pred) / y_true)) * 100 def residcheck(residuals, lags): &quot;&quot;&quot; Function to check if the residuals are white noise. Ideally the residuals should be uncorrelated, zero mean, constant variance and normally distributed. First two are must, while last two are good to have. If the first two are not met, we have not fully captured the information from the data for prediction. Consider different model and/or add exogenous variable. If Ljung Box test shows p&gt; 0.05, the residuals as a group are white noise. Some lags might still be significant. Lags should be min(2*seasonal_period, T/5) from scipy.stats import anderson https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html anderson().statistic &lt;0.05 =&gt; Normal distribution plots from: https://tomaugspurger.github.io/modern-7-timeseries.html &quot;&quot;&quot; resid_mean = np.mean(residuals) lj_p_val = min(ljung(x=residuals, lags=lags)[1]) norm_p_val = anderson(residuals, dist=&#39;norm&#39;).statistic adfuller_p = adfuller(residuals)[1] fig = plt.figure(figsize=(10,8)) layout = (2, 2) ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2); acf_ax = plt.subplot2grid(layout, (1, 0)); kde_ax = plt.subplot2grid(layout, (1, 1)); residuals.plot(ax=ts_ax) plot_acf(residuals, lags=lags, ax=acf_ax); sns.kdeplot(residuals); #[ax.set_xlim(1.5) for ax in [acf_ax, kde_ax]] sns.despine() plt.tight_layout(); print(&quot;** Mean of the residuals: &quot;, resid_mean) print(&quot; n** Ljung Box Test, p-value:&quot;, lj_p_val, &quot;(&gt;0.05, Uncorrelated)&quot; if (lj_p_val &gt; 0.05) else &quot;(&lt;0.05, Correlated)&quot;) print(&quot; n** A-D Normality Test, p_value:&quot;, norm_p_val, &quot;(&lt;0.05, Normal)&quot; if (norm_p_val&lt;0.05) else &quot;(&gt;0.05, Not-normal)&quot;) print(&quot; n** AD Fuller, p_value:&quot;, adfuller_p, &quot;(&gt;0.05, Non-stationary)&quot; if (adfuller_p &gt; 0.05) else &quot;(&lt;0.05, Stationary)&quot;) return ts_ax, acf_ax, kde_ax def accuracy(y1,y2): accuracy_df=pd.DataFrame() rms_error = np.round(rmse(y1, y2),1) map_error = np.round(np.mean(np.abs((np.array(y1) - np.array(y2)) / np.array(y1))) * 100,1) accuracy_df=accuracy_df.append({&quot;RMSE&quot;:rms_error, &quot;%MAPE&quot;: map_error}, ignore_index=True) return accuracy_df . Importing Data . path = &#39;https://github.com/pawarbi/blog/blob/master/data/ts_frenchretail.xlsx?raw=true&#39; #Sales numbers are in thousands, so I am dividing by 1000 to make it easier to work with numbers, especially squared errors data = pd.read_excel(path, parse_dates=True, index_col=&quot;Date&quot;).div(1000) data.index.freq=&#39;Q&#39; data.head() . Sales . Date . 2012-03-31 362.0 | . 2012-06-30 385.0 | . 2012-09-30 432.0 | . 2012-12-31 341.0 | . 2013-03-31 382.0 | . I have explicitly set the index frequency to quarterly. This makes with plotting and analyzing data with pandas plotting easier. More date offsets can be found in Pandas documentation here. freq=&#39;Q-DEC&#39; below shows quarterly data ending in December. Other advantage of setting the &#39;freq&#39; value is that if the dates are not continous, Pandas will throw an error, which can be used to fix the data quality error and make the series continuos. Other common date offsets are: . Monthly Start: &#39;MS&#39; | Quarterly Start: &#39;QS&#39; | Weekly: &#39;W&#39; | Bi Weekly: &#39;2W&#39; | Business/ Weekday: &#39;B | Hourly: &#39;H&#39; | . data.index . DatetimeIndex([&#39;2012-03-31&#39;, &#39;2012-06-30&#39;, &#39;2012-09-30&#39;, &#39;2012-12-31&#39;, &#39;2013-03-31&#39;, &#39;2013-06-30&#39;, &#39;2013-09-30&#39;, &#39;2013-12-31&#39;, &#39;2014-03-31&#39;, &#39;2014-06-30&#39;, &#39;2014-09-30&#39;, &#39;2014-12-31&#39;, &#39;2015-03-31&#39;, &#39;2015-06-30&#39;, &#39;2015-09-30&#39;, &#39;2015-12-31&#39;, &#39;2016-03-31&#39;, &#39;2016-06-30&#39;, &#39;2016-09-30&#39;, &#39;2016-12-31&#39;, &#39;2017-03-31&#39;, &#39;2017-06-30&#39;, &#39;2017-09-30&#39;, &#39;2017-12-31&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;Date&#39;, freq=&#39;Q-DEC&#39;) . Train Test Split: . Before analyzing the data, first split it into train and test(hold-out) for model evaluation. All the EDA and model fitting/selection should be done first using train data. DON&#39;T look at test sample until later to avoid any bias. In this case we want to forecast 4 quarters into the future so test size should be at least 4 or more. I will use last 6 samples as hold-out. Note that in this case I am always selecting the last 6 values for test by using .iloc[:-6]. As we get more data, this will ensure that last 6 values are always for validation. Unlike typical train/test split, we can not shuffle the data before splitting. . Cross-validation: . Data can be split using above method or using cross-validation where the series is split into number of successive segments and model is tested using one-step ahead forecast.Model accuracy in that case is based on mean of the cross-validation errors over the number of splits used. This minimizes chances of overfitting. Be sure include at least 1-2 seasonal periods to capture the seasonality. e.g. in this case, the first training set of the CV should be min 8 values so the model has captured seasonal behaviour from 2 years. This is the preferred method when the time series is short. . In this example, the series has 24 obervations so I can use last 6-8 for validation. When this method is used, always check the sensisitivity of the model performance and model parameters to train/test size. If AIC or AICc is used for model evaluation, it approximatley approaches cross-validation error asymptotically. . Insert picture here of train/test split . train = data.iloc[:-6] test = data.iloc[-6:] #forecast horizon h = 6 train_length = len(train) print(&#39;train_length:&#39;,train_length, &#39; n test_length:&#39;, len(test) ) . train_length: 18 test_length: 6 . Exploratory Data Analysis &amp; Modeling Implications . These are some of the questions I ask at various stages of model building. . Are there any null values? how many? best way to impute the null data? If null/NaNs are present, first identify why the data is missing and if NaNs mean anything. Missing values can be filled by interpolation, forward-fill or backward-fill depending on the data nd context. Also make sure null doesnt mean 0, which is acceptable but has modeling implications. | . | Are the data/dates continuous? In this exmaple I am only looking at continous time-series. There other methods that deal with non-continuous data. ETS &amp; ARIMA require the data to be continuous. | . | Are there any duplicate dates, data? Remove the duplicates or aggregate the data (e.g. average or mean) to treat duplicates | . | Any &#39;potential&#39; outliers? . Outliers are defined as observations that differ significantly from the general observations. Identify if the data is susceptible to outliers/spikes, if outliers mean anything and how to define outliers. While &#39;Outlier Detection&#39; is a topic in itself, in forecasting context we want to treat outliers before the data is used for fitting the model. Both ETS and ARIMA class of models (especially ARIMA) are not robust to outliers and can provide erroneous forecasts. Data should be analyzed while keeping seasonality in mind. e.g. a sudden spike could be because of the seasonal behaviour. . | Few ways to treat outliers: . Use Box and whiskers and clip the values tha exceed 1 &amp; 99th percentile | Use residual standard deviation and compare against observed values | Use moving average to check spikes/troughs | . | Another important reason to pay close attention to outliers is that we will choose the appropriate error metric based on that. There are many error metrics used to assess accuracy of forecasts, viz. MAE, MSE, RMSE, %MAPE, %sMAPE. If outliers are present, don&#39;t use RMSE because the squaring the error at the outlier value can inflate the RMSE. In that case model should be selected/assessed using %MAPE or %sMAPE. More on that later. . | . | Visually any trend, seasonality, cyclic behaviour? This will help us choose the appropriate model (Single, Double, Triple Exponential Smoothing, ARIMA/SARIMA) | If cyclic behiour is present (seasonality is short-order variation e.g. month/quarter, cyclicity occurs over 10-20 years e.g. recession) we will need to use different type of ETS model (X11, STL). Depending on the context and purpose of analysis, seasoanlity adjustment may also be needed. | If multiple seasonalities are present, ETS or ARIMA cannot be used. SSA, TBATS, harmonic regression are more appropriate in that case. | Frequency of seasonality is importnat. ETS &amp; SARIMAX are nor appropriate for high frequency data such as hourly, daily, sub-daily and even weekly. Consider using SSA,TBTAS, FB Prophet, deep learning models. | . | How does the data change from season to season for each year? Does it increas/decrease with the trend? Changes slowly, rapidly or remains constant. This is an important observation to be made, especially for ETS model, as it can determine the parametrs to be used &amp; if any preprocessing will be needed. | . | 7. How does the data change from year to year? . Distribution of the data? will we need any transformations? While normally distributed data is not a requirement for forecasting and doesnt necessarily improve point forecast accuracy, it can help stablize the variance and narrow the prediction interval. | Plot the histogram/KDE for each time period (e.g. each year and each seasona) to get gauge peakedness, spread in the data. It can also help compare different periods and track trends over time. | If the data is severely skewed, consider normalizing the data before training the model. Be sure to apply inverse transformation on the forecasts. Use the same transformation parameters on the train and test sets. Stabilizing the variance by using Box Cox transformation (special case being log &amp; inverse transform), power law etc can help more than normalizing the data. | Watch out for outliers before transformation as it will affect the transformation | Plottng distribution also helps track &quot;concept-drift&quot; in the data, i.e. does the underlying temporal structure / assumption change over time. If the drift is significant, refit the model or at least re-evaluate. This can be tricky in time series analysis. | Uncertainty in the training data will lead to higher uncertainty in the forecast. If the data is highly volatile/uncertain (seen by spread in the distribution, standard deviation, non-constant variance etc), ETS and ARIMA models will not be suitable. Consider GARCH and other methods. | . | Is the data stationary? Is this a white noise, random walk process? . Perhaps the most important concept to keep in mind when doing time series analysis and forecasting is that, time series is a probabilistic / stochastic process, and the time series we are analyzing is a &#39;realization of a stochastic process&#39;. A time signal could be deterministic or stochastic/probabilistic. In a deterministic process, the future values can be predicted exactly with a mathematical function e.g. y = sin(2$ pi$ft). In our case, the future values can only be expressed in terms of probability distribution. The point estimates are mean/median of the distribution. By definition, the mean has a distribution around it and as such the stakeholders should be made aware of the probabilistic nature of the forecast through uncertainty estimates. . | Stationarity: Statistical stationarity means the time series has constant mean, variance and autocorrelation is insignificant at all lags. Autocorrelation is a mouthful, all it means is the correlation with its past self. e.g. to check if two variables are linearly correlated with each other, we calculate their coeff of correlation (Pearson correlation). Similarly, autocorrelation does the same thing but with its past values (i.e lags). More on that later. For a stationary time series, the properties are the same no matter which part of the series (w.r.t time) we look at. This is a core concept of the ARIMA methods, as only sttaionary processes can be modeled using ARIMA. ETS can handle non-stationary processes. . | White Noise: If a time series has zero mean and a constant variance $ sigma^2$, it&#39;s a white noise. The variables in this case are independent and identically distributed (i.i.d) and are uncorrelated. We want the residuals left after fitting the model to be a white noise. White noise can be identified by using ADFuller test and plotting autocorrelation function (ACF) plots. | Random Walk: Random walks are non-stationary. It&#39;s mean or variance or both changes over time. Random walk cannot be forecast because we have more unknowns than the data so we will end up having way to many parameters in the model. In essence, random walk has no pattern to it, it&#39;s last data point plus some random signal (drift). Thus, if the first difference of the time series results in a white noise, it&#39;s an indication of a Random Walk. Most equity stocks are random walk but by looking at percent difference (%growth over time) we can study the white noise. | . | Next data point = Last Data point + Random Noise =&gt; Next Data Point - Last Data Point = Random Noise (i.e White noise) - . Auto-correlation? at what lag? | If trend is present, momentum or mean-reversing? | Break-points in the series? | Intermittent demand? | #Any missing data? print(&quot;missing_data:&quot;, train.isna().sum()) print(&quot;unique dates:&quot;, train.index.nunique()) . missing_data: Sales 0 dtype: int64 unique dates: 18 . pd.date_range() . pd.crosstab(index=train.index.year, columns=train.index.quarter) . col_0 1 2 3 4 . row_0 . 2012 1 | 1 | 1 | 1 | . 2013 1 | 1 | 1 | 1 | . 2014 1 | 1 | 1 | 1 | . 2015 1 | 1 | 1 | 1 | . 2016 1 | 1 | 0 | 0 | . Observations: . No null values | Length of the train set is 12 and we have 12 unique dates/quarters so no duplicate dates | Each year and quarter has 1 observation, so no duplicates and data is continuous | train_chart=alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;Date&#39;, y=&#39;Sales&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]) rolling_mean = alt.Chart(train.reset_index()).mark_trail( color=&#39;orange&#39;, size=1 ).transform_window( rolling_mean=&#39;mean(Sales)&#39;, frame=[-4,4] ).encode( x=&#39;Date:T&#39;, y=&#39;rolling_mean:Q&#39;, size=&#39;Sales&#39; ) (train_chart + rolling_mean).properties(width=800) . green : #4daa4e 77 170 78 . red: #d6555c rgb(214, 85, 92) . orange: #ff8c0f rgb(255, 161, 40) . blue: #4d6eae rgb(77, 110, 174) . alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;quarter(Date)&#39;, y=&#39;Sales&#39;, column=&#39;year(Date)&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]).properties( width=100) . alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;year(Date)&#39;, y=&#39;Sales&#39;, column=&#39;quarter(Date)&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]).properties( width=100) . Observations: . Sales goes up from Q1 to Q3, peaks in Q3, drops in Q4. Definitely a seasoanl pattern. =&gt; Model should capture seasonality | Just comparing Q4 peaks, sales has gone up from $432K to $582K =&gt; Trend exists, Model should capture trend. No cyclic behaviour | Overall data looks clean and &#39;visually&#39; no outliers or anamolies =&gt; won&#39;t need any data cleaning or filtering | Quarterly / Yearly trends &amp; distrbution . #Quarterly plot: Shows trend for Q1-Q4 for each of the years. Red line shows mean quarter_plot(train); . sns.distplot(train, label=&#39;Train&#39;, hist=False) sns.distplot(train[&#39;2012&#39;], label=&#39;2012&#39;, hist=False) sns.distplot(train[&#39;2013&#39;], label=&#39;2013&#39;, hist=False) sns.distplot(train[&#39;2014&#39;], label=&#39;2014&#39;, hist=False) sns.distplot(train[&#39;2015&#39;], label=&#39;2015&#39;, hist=False); . sns.heatmap(pd.pivot_table(data=train, index=train.index.year, columns=train.index.quarter), square=True, cmap=&#39;Blues&#39;, xticklabels=[&quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;, &quot;Q4&quot;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x18ff0a3d208&gt; . Observations: . Quarter plot &amp; heatmap confirms peak in Q3, drop in Q4. | For each of the years the upward trend observed in all quarters | Kenel Density plot shows somewhat normal distribution, (bi-modal). Peaks shifts from 2012 to 2014 indicating increase in mean. Overall distribution profile is consistent across the years. =&gt; mean centering/scaling likely not needed | 2nd order properties of the time series . #Is the data stationary? train.plot(figsize=(12,8), legend=True, label=&quot;Train&quot;, cmap=&#39;gray&#39;) train[&quot;Sales&quot;].rolling(3).mean().plot(legend=True, label=&quot;Rolling Mean 3Q&quot;); . train[&quot;Sales&quot;].rolling(3).std().plot(legend=True, label=&quot;Rolling Std Deviation 3Q&quot;); . Visually mean and std dev change over time =&gt; Not stationary. . plot_acf(train); plot_pacf(train); . Observations: . ACF: Very interesting. auto-correlation plot shows autocorrelation coeff is insignificant at all lag values (within the blue 95%CI band). Note that coeff sign changed after 4 lags indicating seasonal pattern with seasonal_period=4 (which we already knew since tihs is a quarterly data). Also, alternating pattern shows mean-reversion process. since AC coeff is not significant likley MA(q=0) process | PACF: At lag 1, barely within the 95% CI but significant at lags 5,6,7,8,9,10,11, 12. Significant peak at 8 which is harmonic of 4. Alternating pattern shows seasonal behaviour. Significant peaks show AR process. Differencing would be needed to make the data stationary. =&gt; For ARIMA model ~ ARIMA(1,1,0)?? | #Let&#39;s try differencing d=1 to de-trend the series de_trended = train.diff(1).dropna() de_trended.plot(label=&quot;De-trended&quot;, legend=True) plot_pacf(de_trended); . plot_acf(diff(train, 1,1,4)); plot_pacf(diff(train, 1,1,4)); . Differencing didnot help stationarize the series ! . #Statistical test for stationarity adfuller(train[&quot;Sales&quot;]) . (2.452618859692341, 0.9990329594016152, 7, 10, {&#39;1%&#39;: -4.331573, &#39;5%&#39;: -3.23295, &#39;10%&#39;: -2.7487}, 212.6280742064206) . p = 0.99 which is &gt;0.05. Time series is not stationary . #Shapiri-Wilcox test for normality. if p&lt; 0.05, data is normal sm.stats.diagnostic.kstest_normal(train[&quot;Sales&quot;],&quot;norm&quot;)[1] . 0.7165057864636755 . Series is not normally distributed . De-trended series, ACF/PACF plots show seasonality=4 since this is a quarterly data. I am going to try Power Spectrum analysis to see if there are any other frequencies/signals . Summary: What do I know so far? . Trend &amp; seasonality present. My guess trend=additive, seasonal =&quot;add/mul&quot;, seasonal_periods=4, no damping, since differencing didnot help, highly non-stationary, ETS residual may be non-normal | Normally distributed, boxcox, log, scaling transofmration likley not needed | No outliers to treat | Likley AR process with high order differencing for SARIMA | anderson(train[&quot;Sales&quot;]).statistic . 0.29859509940060747 . ETS Model . Decompose the series into trend, season and resid. Goals: . Is the trend linear, linear exponential, damped | Seasonality? | Are the residuals normal? If the residuals are not normal, point-forecasts will still be accurate but the prediction intervals wont be. Bootstrapping maybe needed | decompose = seasonal_decompose(train) decompose.plot(); . f, fx = signal.periodogram(decompose.seasonal.values) freq=f.reshape(len(f),1) #reshape the array to a column amplitude = fx.reshape(len(f),1) plt.plot(1/freq, amplitude ); . Power Spectral analysis shows a peak at 4 =&gt; seasonality =4 . fig, ax = plt.subplots(sharex=True, sharey=True) train.plot(legend=True, label=&quot;Train&quot;, sharex=True, ax=ax) decompose.trend.plot(legend=True, label=&quot;Train&quot;,ax=ax) plt.figure(figsize=(12,9)) plt.show() . &lt;Figure size 864x648 with 0 Axes&gt; . Trend does look exponential. Do we need boxcox? may be not but worth trying. . #Distribution of the residual. Not normal. be sure to run diagnostics on the fitted model&#39;s residuals decompose.resid.hist(); . Grid-searching ETS model . Grid Searching the parameter space . model_ses = SimpleExpSmoothing(train[&quot;Sales&quot;]).fit() model1=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit() model2=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit() model3=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;mul&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit() model4=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;mul&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit() model5=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit(use_boxcox=True) model6=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit(use_boxcox=True) print(&quot;Train RMSE, MAPE:&quot;, &quot; n SES: &quot;, rmse(train[&quot;Sales&quot;],model_ses.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model_ses.fittedvalues), &quot; n model1:&quot;, rmse(train[&quot;Sales&quot;],model1.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model1.fittedvalues), &quot; n model2:&quot;, rmse(train[&quot;Sales&quot;],model2.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model2.fittedvalues), &quot; n model3:&quot;, rmse(train[&quot;Sales&quot;],model3.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model3.fittedvalues), &quot; n model4:&quot;, rmse(train[&quot;Sales&quot;],model4.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model4.fittedvalues), &quot; n model5:&quot;, rmse(train[&quot;Sales&quot;],model5.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model5.fittedvalues), &quot; n model6:&quot;, rmse(train[&quot;Sales&quot;],model6.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model6.fittedvalues), ) . Train RMSE, MAPE: SES: 67196.83727676631 , 11.737847424882816 model1: 18169.415979095116 , 2.421781848260075 model2: 15131.10006066934 , 2.1284667721448605 model3: 19709.0984764635 , 2.9819826581436972 model4: 12248.838186205909 , 2.311953374582752 model5: 15390.048459667778 , 2.2660607344163934 model6: 15473.587112631554 , 2.2844527000583903 . accuracy(train[&quot;Sales&quot;],model6.fittedvalues) . %MAPE RMSE . 0 2.3 | 15473.6 | . Residual Check . Check the residuals. Run Ljung Box test for white noise and see if residuals are uncorrelated. For lags use: . Seasonal min(2m, T/5), non-seasonal: (10,T/5) -- https://robjhyndman.com/hyndsight/ljung-box-test/ . Residuals should be: . Uncorrelated (Ljung Box) | Zero mean (Ljung Box) | Constant variance (for prediction interval) | Normal (for prediction interval) | residcheck(model1.resid, 10); . ** Mean of the residuals: 4937.902751839591 ** Ljung Box Test, p-value: 0.5197061335692237 (&gt;0.05, Uncorrelated) ** A-D Normality Test, p_value: 1.2654780573669022 (&gt;0.05, Not-normal) ** AD Fuller, p_value: 0.0012050606212250445 (&lt;0.05, Stationary) . sm.stats.diagnostic.kstest_normal(model1.resid,&quot;norm&quot;)[1] . 0.005477051755401487 . train.plot(legend=True, label=&quot;Sales Data&quot;, figsize=(12,8), cmap=&#39;gray&#39;, style=&#39;--&#39;) model2.predict(1, len(train)).plot(legend=True, label=&quot;without log&quot;) model6.predict(1, len(train)).plot(legend=True, label=&quot;log&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x184f7e1d898&gt; . #data.plot(legend=True, label=&quot;Sales Data&quot;, figsize=(20,8), cmap=&#39;gray&#39;, style=&#39;--&#39;) test.plot(legend=True, label=&quot;Test&quot;, figsize=(20,8), style=&#39;--&#39;) model2.predict(1, len(data)+6).plot(legend=True, label=&quot;without log&quot;) model6.predict(1, len(data)+6).plot(legend=True, label=&quot;log&quot;) model1.predict(1, len(data)+6).plot(legend=True, label=&quot;add&quot;) model3.predict(1, len(data)+6).plot(legend=True, label=&quot;model3&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x184f7d99780&gt; . %%R -i train -o ets_summary library(fpp2) r_train &lt;- ts(train$Sales, start=c(2012,03,31), frequency=4) ets_summary &lt;- r_train %&gt;% ets() . #Using tsCV . %%R -i data -o mean_e,mean_e2,mean_e3,mean_e_arima,mean_e_arima_box,lam r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) lam &lt;- BoxCox.lambda(r_data) fets1 &lt;- function(x, h) { forecast(ets(x), h = h) } e &lt;- tsCV(r_data, fets, h=1) mean_e=mean(e^2, na.rm=TRUE) #with log fets2 &lt;- function(x, h) { forecast(ets(x, lambda=0), h = h) } e_log &lt;- tsCV(r_data, fets2, h=1) mean_e2=mean(e_log^2, na.rm=TRUE) #with BoxCox fets3 &lt;- function(x, h) { forecast(ets(x, lambda=lam), h = h) } e_box &lt;- tsCV(r_data, fets3, h=1) mean_e3=mean(e_box^2, na.rm=TRUE) #with ARIMA farima &lt;- function(x, h) { forecast(auto.arima(x), h = h) } e_arima &lt;- tsCV(r_data, farima, h=1) mean_e_arima=mean(e_arima^2, na.rm=TRUE) #with ARIMA &amp; BoxCox farima_box &lt;- function(x, h) { forecast(auto.arima(x, lambda=lam), h = h) } e_arima2 &lt;- tsCV(r_data, farima_box, h=1) mean_e_arima_box=mean(e_arima2^2, na.rm=TRUE) . %%R -i data -o mean_e_MAM,mean_e_AAA,mean_e2 r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) lam &lt;- BoxCox.lambda(r_data) fets_MAM &lt;- function(x, h) { forecast(ets(x, model=&#39;MAM&#39;), h = h) } e_MAM &lt;- tsCV(r_data, fets_MAM, h=1) mean_e_MAM=mean(e_MAM^2, na.rm=TRUE) fets_AAA &lt;- function(x, h) { forecast(ets(x, model=&#39;AAA&#39;), h = h) } e_AAA &lt;- tsCV(r_data, fets_AAA, h=1) mean_e_AAA=mean(e_AAA^2, na.rm=TRUE) #with log fets_MAM_log &lt;- function(x, h) { forecast(ets(x,model=&#39;MAM&#39;, lambda=lam), h = h) } e_log &lt;- tsCV(r_data, fets_MAM_log, h=1) mean_e2=mean(e_log^2, na.rm=TRUE) . print(mean_e_MAM,mean_e_AAA,mean_e2, end=&quot;&quot;) . [1] 2413822041 [1] 2736208289 [1] NaN . %%R -i data -o ets_summary2 library(fpp2) r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) ets_summary2 &lt;- r_data %&gt;% ets() . print(ets_summary) . ETS(M,A,M) Call: ets(y = .) Smoothing parameters: alpha = 0.8309 beta = 0.0055 gamma = 1e-04 Initial states: l = 338029.7256 b = 17199.4484 s = 0.8732 1.1323 1.0171 0.9773 sigma: 0.0411 AIC AICc BIC 415.7237 438.2237 423.7370 . model2.summary() . ExponentialSmoothing Model Results Dep. Variable: endog | No. Observations: 18 | . Model: ExponentialSmoothing | SSE 4121103402.828 | . Optimized: True | AIC 362.482 | . Trend: Additive | BIC 369.605 | . Seasonal: Multiplicative | AICC 393.911 | . Seasonal Periods: 4 | Date: Thu, 19 Mar 2020 | . Box-Cox: False | Time: 19:10:57 | . Box-Cox Coeff.: None | | . | coeff code optimized . smoothing_level 0.5789474 | alpha | True | . smoothing_slope 0.5789474 | beta | True | . smoothing_seasonal 0.1052632 | gamma | True | . initial_level 4.778e+05 | l.0 | True | . initial_slope 9750.0000 | b.0 | True | . initial_seasons.0 0.7712350 | s.0 | True | . initial_seasons.1 0.8109963 | s.1 | True | . initial_seasons.2 0.8992978 | s.2 | True | . initial_seasons.3 0.6952976 | s.3 | True | . %%R install.packages(&#39;dplyr&#39;) . data.tail() . Sales . Date . 2016-12-31 592000 | . 2017-03-31 627000 | . 2017-06-30 725000 | . 2017-09-30 854000 | . 2017-12-31 661000 | . data.head() . Sales . Date . 2012-03-31 362000 | . 2012-06-30 385000 | . 2012-09-30 432000 | . 2012-12-31 341000 | . 2013-03-31 382000 | . %R install.packages(&quot;rlang&quot;) . source = data.reset_index() . source = data.reset_index() rolling = source[&quot;Sales&quot;].rolling(3).mean() . base = alt.Chart(source).encode(x=&#39;Date&#39;) data = base.mark_line().encode(y=&quot;Sales&quot;) roll = alt.Chart(rolling).encode(x=&#39;Date&#39;, y=&#39;Sales&#39;) . alt.Chart(source).transform_density( &#39;Sales&#39;, as_=[&#39;Sales&#39;, &#39;density&#39;], extent = [0,1200] ).mark_area().encode( x=&quot;Sales:Q&quot;, y=&#39;density:Q&#39;, ) .",
            "url": "https://pawarbi.github.io/blog/2020/03/30/2020-03-28-timeseries.html",
            "relUrl": "/2020/03/30/2020-03-28-timeseries.html",
            "date": " â€¢ Mar 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Time series Forecasting in Python & R",
            "content": "Project Goals . This is a quarterly sales data of a French retail company from Prof. Rob Hyndman&#39;s &quot;Forecasting Methods &amp; Applications&quot; book. I have uploaded the data to my github. I chose this example because it&#39;s deceptively simple, easy to explain/demonstrate key concepts and Prof. Hyndman later applied the state space approach to this series using family of ETS models. The goals for this project are: . Forecast 1 year ahead , i.e next 4 quarters | Create a forecast pipeline using Python first &amp; later R for comparison purposes | Compare various forecasting methods &amp; choose the best model. Evaluate the models using various evaluation criteria. | Focus on explanability and identify how EDA informs the model selection | Dcoument my findings &amp; notes to self | Importing libraries . #collapse-hide #Author: Sandeep Pawar #Version: 1.0 #Date Mar 27, 2020 import pandas as pd import numpy as np import itertools #Plotting libraries import matplotlib.pyplot as plt import seaborn as sns import altair as alt %matplotlib inline #statistics libraries import statsmodels.api as sm import scipy from scipy.stats import anderson from statsmodels.tools.eval_measures import rmse from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot from statsmodels.tsa.seasonal import seasonal_decompose from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing from statsmodels.stats.diagnostic import acorr_ljungbox as ljung #from nimbusml.timeseries import SsaForecaster from statsmodels.tsa.statespace.tools import diff as diff import pmdarima as pm from pmdarima import ARIMA, auto_arima from scipy import signal from scipy.stats import shapiro from scipy.stats import boxcox #library to use R in Python import rpy2 from rpy2.robjects import pandas2ri pandas2ri.activate() #%load_ext rpy2.ipython import warnings warnings.filterwarnings(&quot;ignore&quot;) . . . Note: I have found that results could be significanlty different if you use different version of the libraries, especially with statsmodels &amp; rpy2. So if you want to reproduce these results, be sure to use the same versions of these libraries. For this project, I created a conda virtual environment as rpy2 requires specific versions of Pandas &amp; certain R libraries . #Printing library versions print(&#39;Pandas:&#39;, pd.__version__) print(&#39;Statsmodels:&#39;, sm.__version__) print(&#39;Scipy:&#39;, scipy.__version__) print(&#39;Rpy2:&#39;, rpy2.__version__) . Pandas: 0.25.0 Statsmodels: 0.11.0 Scipy: 1.4.1 Rpy2: 2.9.4 . #collapse-hide # Define some custom functions to help the analysis def MAPE(y_true, y_pred): &quot;&quot;&quot; %Error compares true value with predicted value. Lower the better. Use this along with rmse(). If the series has outliers, compare/select model using MAPE instead of rmse() &quot;&quot;&quot; y_true, y_pred = np.array(y_true), np.array(y_pred) return np.mean(np.abs((y_true - y_pred) / y_true)) * 100 def residcheck(residuals, lags): &quot;&quot;&quot; Function to check if the residuals are white noise. Ideally the residuals should be uncorrelated, zero mean, constant variance and normally distributed. First two are must, while last two are good to have. If the first two are not met, we have not fully captured the information from the data for prediction. Consider different model and/or add exogenous variable. If Ljung Box test shows p&gt; 0.05, the residuals as a group are white noise. Some lags might still be significant. Lags should be min(2*seasonal_period, T/5) from scipy.stats import anderson https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html anderson().statistic &lt;0.05 =&gt; Normal distribution plots from: https://tomaugspurger.github.io/modern-7-timeseries.html &quot;&quot;&quot; resid_mean = np.mean(residuals) lj_p_val = min(ljung(x=residuals, lags=lags)[1]) norm_p_val = anderson(residuals, dist=&#39;norm&#39;).statistic adfuller_p = adfuller(residuals)[1] fig = plt.figure(figsize=(10,8)) layout = (2, 2) ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2); acf_ax = plt.subplot2grid(layout, (1, 0)); kde_ax = plt.subplot2grid(layout, (1, 1)); residuals.plot(ax=ts_ax) plot_acf(residuals, lags=lags, ax=acf_ax); sns.kdeplot(residuals); #[ax.set_xlim(1.5) for ax in [acf_ax, kde_ax]] sns.despine() plt.tight_layout(); print(&quot;** Mean of the residuals: &quot;, resid_mean) print(&quot; n** Ljung Box Test, p-value:&quot;, lj_p_val, &quot;(&gt;0.05, Uncorrelated)&quot; if (lj_p_val &gt; 0.05) else &quot;(&lt;0.05, Correlated)&quot;) print(&quot; n** A-D Normality Test, p_value:&quot;, norm_p_val, &quot;(&lt;0.05, Normal)&quot; if (norm_p_val&lt;0.05) else &quot;(&gt;0.05, Not-normal)&quot;) print(&quot; n** AD Fuller, p_value:&quot;, adfuller_p, &quot;(&gt;0.05, Non-stationary)&quot; if (adfuller_p &gt; 0.05) else &quot;(&lt;0.05, Stationary)&quot;) return ts_ax, acf_ax, kde_ax def accuracy(y1,y2): accuracy_df=pd.DataFrame() rms_error = np.round(rmse(y1, y2),1) map_error = np.round(np.mean(np.abs((np.array(y1) - np.array(y2)) / np.array(y1))) * 100,1) accuracy_df=accuracy_df.append({&quot;RMSE&quot;:rms_error, &quot;%MAPE&quot;: map_error}, ignore_index=True) return accuracy_df . . Importing Data . path = &#39;https://raw.githubusercontent.com/pawarbi/datasets/master/timeseries/ts_frenchretail.csv&#39; #Sales numbers are in thousands, so I am dividing by 1000 to make it easier to work with numbers, especially squared errors data = pd.read_csv(path, parse_dates=True, index_col=&quot;Date&quot;).div(1000) data.index.freq=&#39;Q&#39; data.head() . Sales . Date . 2012-03-31 362.0 | . 2012-06-30 385.0 | . 2012-09-30 432.0 | . 2012-12-31 341.0 | . 2013-03-31 382.0 | . . Note: I have explicitly set the index frequency to quarterly. This makes plotting and analyzing data with pandas and statsmodels easier. Many methods in Statsmodels have freq argument. Setting the frequency explicitly will pass the value automatically. More date offsets can be found in Pandas documentation here. freq=&amp;#8217;Q-DEC&amp;#8217; below shows quarterly data ending in December. Other advantage of setting the .freq value is that if the dates are not continous, Pandas will throw an error, which can be used to fix the data quality error and make the series continuos. Other common date offsets are: - Monthly Start: &#39;MS&#39; . Quarterly Start: &#39;QS&#39; | Weekly: &#39;W&#39; | Bi Weekly: &#39;2W&#39; | Business/ Weekday: &#39;B&#39; | Hourly: &#39;H&#39; | . data.index . DatetimeIndex([&#39;2012-03-31&#39;, &#39;2012-06-30&#39;, &#39;2012-09-30&#39;, &#39;2012-12-31&#39;, &#39;2013-03-31&#39;, &#39;2013-06-30&#39;, &#39;2013-09-30&#39;, &#39;2013-12-31&#39;, &#39;2014-03-31&#39;, &#39;2014-06-30&#39;, &#39;2014-09-30&#39;, &#39;2014-12-31&#39;, &#39;2015-03-31&#39;, &#39;2015-06-30&#39;, &#39;2015-09-30&#39;, &#39;2015-12-31&#39;, &#39;2016-03-31&#39;, &#39;2016-06-30&#39;, &#39;2016-09-30&#39;, &#39;2016-12-31&#39;, &#39;2017-03-31&#39;, &#39;2017-06-30&#39;, &#39;2017-09-30&#39;, &#39;2017-12-31&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;Date&#39;, freq=&#39;Q-DEC&#39;) . Train Test Split: . Before analyzing the data, first split it into train and test(hold-out) for model evaluation. All the EDA and model fitting/selection should be done first using train data. DON&#39;T look at test sample until later to avoid any bias. In this case we want to forecast 4 quarters into the future so test size should be at least 4 or more. I will use last 6 samples as hold-out. Note that in this case I am always selecting the last 6 values for test by using .iloc[:-6]. As we get more data, this will ensure that last 6 values are always for validation. Unlike typical train/test split, we can not shuffle the data before splitting. Also note that more data is not necessarily a good thing. Before adding more data, make sure you understand the data context. . Cross-validation: . Data can be split using above method or using cross-validation where the series is split into number of successive segments and model is tested using one-step ahead forecast.Model accuracy in that case is based on mean of the cross-validation errors over the number of splits used. This minimizes chances of overfitting. Be sure include at least 1-2 seasonal periods to capture the seasonality. e.g. in this case, the first training set of the CV should be min 8 values so the model has captured seasonal behaviour from 2 years. This is the preferred method when the time series is short. . In this example, the series has 24 obervations so I can use last 6-8 for validation. When this method is used, always check the sensisitivity of the model performance and model parameters to train/test size. If AIC or AICc is used for model evaluation, it approximatley approaches cross-validation error asymptotically. . Insert picture here of train/test split . train = data.iloc[:-6] test = data.iloc[-6:] #forecast horizon h = 6 train_length = len(train) print(&#39;train_length:&#39;,train_length, &#39; n test_length:&#39;, len(test) ) . train_length: 18 test_length: 6 . Exploratory Data Analysis &amp; Modeling Implications . These are some of the questions I ask at various stages of model building. . Are there any null values? how many? best way to impute the null data? If null/NaNs are present, first identify why the data is missing and if NaNs mean anything. Missing values can be filled by interpolation, forward-fill or backward-fill depending on the data nd context. Also make sure null doesnt mean 0, which is acceptable but has modeling implications. | . | Are the data/dates continuous? In this exmaple I am only looking at continous time-series. There other methods that deal with non-continuous data. ETS &amp; ARIMA require the data to be continuous. If the series is not continuous, we can add dummy data or use interpolation. | . | Are there any duplicate dates, data? Remove the duplicates or aggregate the data (e.g. average or mean) to treat duplicates | . | Any &#39;potential&#39; outliers? . Outliers are defined as observations that differ significantly from the general observations. Identify if the data is susceptible to outliers/spikes, if outliers mean anything and how to define outliers. While &#39;Outlier Detection&#39; is a topic in itself, in forecasting context we want to treat outliers before the data is used for fitting the model. Both ETS and ARIMA class of models (especially ARIMA) are not robust to outliers and can provide erroneous forecasts. Data should be analyzed while keeping seasonality in mind. e.g. a sudden spike could be because of the seasonal behaviour and not be outlier. Do not confuse outlier with &#39;influential data&#39;. . | Few ways to treat outliers: . Winsorization: Use Box and whiskers and clip the values tha exceed 1 &amp; 99th percentile (not preferred) | Use residual standard deviation and compare against observed values (preferred but can&#39;t do a priori) | Use moving average to check spikes/troughs | . | Another important reason to pay close attention to outliers is that we will choose the appropriate error metric based on that. There are many error metrics used to assess accuracy of forecasts, viz. MAE, MSE, RMSE, %MAPE, %sMAPE. If outliers are present, don&#39;t use RMSE because the squaring the error at the outlier value can inflate the RMSE. In that case model should be selected/assessed using %MAPE or %sMAPE. More on that later. . | . | Visually any trend, seasonality, cyclic behaviour? This will help us choose the appropriate model (Single, Double, Triple Exponential Smoothing, ARIMA/SARIMA) | If cyclic behiour is present (seasonality is short-order variation e.g. month/quarter, cyclicity occurs over 10-20 years e.g. recession) we will need to use different type of decomposition (X11, STL). Depending on the context and purpose of analysis, seasoanlity adjustment may also be needed. | If multiple seasonalities are present, ETS or ARIMA cannot be used. SSA, TBATS, harmonic regression are more appropriate in that case. FB Prophet can also help with multiple seasonalities. | Frequency of seasonality is important. ETS &amp; SARIMAX are not appropriate for high frequency data such as hourly, daily, sub-daily and even weekly. Consider using SSA,TBTAS, FB Prophet, deep learning models. | . | How does the data change from season to season for each period and period to period? Does it increas/decrease with the trend? Changes slowly, rapidly or remains constant. This is an important observation to be made, especially for ETS model, as it can determine the parametrs to be used &amp; if any preprocessing will be needed. | . | Distribution of the data? will we need any transformations? While normally distributed data is not a requirement for forecasting and doesnt necessarily improve point forecast accuracy, it can help stablize the variance and narrow the prediction interval. | Plot the histogram/KDE for each time period (e.g. each year and each seasona) to get gauge peakedness, spread in the data. It can also help compare different periods and track trends over time. | If the data is severely skewed, consider normalizing the data before training the model. Be sure to apply inverse transformation on the forecasts. Use the same transformation parameters on the train and test sets. Stabilizing the variance by using Box Cox transformation (special case being log &amp; inverse transform), power law etc can help more than normalizing the data. | Watch out for outliers before transformation as it will affect the transformation | Plottng distribution also helps track &quot;concept-drift&quot; in the data, i.e. does the underlying temporal structure / assumption change over time. If the drift is significant, refit the model or at least re-evaluate. This can be tricky in time series analysis. | Uncertainty in the training data will lead to higher uncertainty in the forecast. If the data is highly volatile/uncertain (seen by spread in the distribution, standard deviation, non-constant variance etc), ETS and ARIMA models will not be suitable. Consider GARCH and other methods. | . | Is the data stationary? Is this a white noise, random walk process? . Perhaps the most important concept to keep in mind when doing time series analysis and forecasting is that, time series is a probabilistic / stochastic process, and the time series we are analyzing is a &#39;realization of a stochastic process&#39;. A time signal could be deterministic or stochastic/probabilistic. In a deterministic process, the future values can be predicted exactly with a mathematical function e.g. y = sin(2$ pi$ft). In our case, the future values can only be expressed in terms of probability distribution. The point estimates are mean/median of the distribution. By definition, the mean has a distribution around it and as such the stakeholders should be made aware of the probabilistic nature of the forecast through uncertainty estimates. . | Stationarity: Statistical stationarity means the time series has constant mean, variance and autocorrelation is insignificant at all lags. Autocorrelation is a mouthful, all it means is the correlation with its past self. e.g. to check if two variables are linearly correlated with each other, we calculate their coeff of correlation (Pearson correlation). Similarly, autocorrelation does the same thing but with its past values (i.e lags). More on that later. For a stationary time series, the properties are the same no matter which part of the series (w.r.t time) we look at. This is a core concept of the ARIMA methods, as only stationary processes can be modeled using ARIMA. ETS can handle non-stationary processes. . | White Noise: If a time series has zero mean and a constant variance $ sigma^2$, it&#39;s a white noise. The variables in this case are independent and identically distributed (i.i.d) and are uncorrelated. We want the residuals left after fitting the model to be a white noise. White noise can be identified by using ADFuller test and plotting autocorrelation function (ACF) plots. | Random Walk: Random walks are non-stationary. It&#39;s mean or variance or both change over time. Random walk cannot be forecast because we have more unknowns than the data so we will end up having way too many parameters in the model. In essence, random walk has no pattern to it, it&#39;s last data point plus some random signal (drift). Thus, if the first difference of the time series results in a white noise, it&#39;s an indication of a Random Walk. e.g. most equity stocks are random walk but by looking at percent difference (%growth over time) we can study the white noise. | . | `Next data point = Last Data point + Random Noise` `Next Data Point - Last Data Point = Random Noise (i.e White noise)` . Auto-correlation? at what lag? Study the second order properties (autocorrelation and power spectral density) of the time series along with mean, standard deviation, distribution. | . | If trend is present, momentum or mean-reversing? . Time series with momentum indicates the value tends to keep going up or down (relative to trend) depending on the immediate past. Series with mean-reversion indicates it will go up (or down) if it has gone down (or up) in the immediate past. This can be found by examining the coefficients of the ARIMA model. This provides more insight into the process and builds intuition. This doesnt not directly help with forecasting. | . | Break-points in the series? . Are there any structural breaks (shifts) in the series. Structural breaks are abrupt changes in the trend. Gather more information about the sudden changes. If the breaks are valid, ETS/ARIMA models wont work. FB Prophet, dynamic regression, deep learning models, adding more features might help. Identify the possible reasons for change, e.g. change in macros, price change, change in customer preferenaces etc. Note structural change persists for some time, while outliers do not. Break points are different from non-stationarity. Read more here for examples &amp; explanations. In case of structural break-points, consider modeling the segments of the series separately. | . | Intermittent demand? Time series is said to be intermittent when there are several 0 and small values (not nulls) in the series. ETS and ARIMA are not appropriate for this type of time series. It&#39;s a common pattern with inventory time series, especially for new items. Croston&#39;s method is one approach to use for forecasting intermittent demand. | When demand is intermittent, use RMSE rather than %MAPE as the evaluation metric. With %MAPE, the denominator would be 0 leading to erroneous results. | . | Do we need any exogenous variables/external regressors? It may be necessary to include additional features/variables to accurately capture the time series behaviour. For example, the sales for a retailer might be higher on weekends, holidays and lower on weekdatys etc. This is different from seasonal pattern. In such cases, using the &#39;day of the week&#39; or &#39;is_holiday&#39; feature might provide better forecast. ETS models cannot use exogenous variable. SARIMAX (X is for exogenous), deep learning, XGB models can be more suited. | Always inspect the residuals after fitting the model. If the residuals are correlated (use ACF/PACF plots, Ljung Box test on residuals), it&#39;s an indication that we are not capturing the time series behaviour accurately and could try adding exogenous behaviour. | . | #Any missing data? print(&quot;missing_data:&quot;, train.isna().sum()) print(&quot;unique dates:&quot;, train.index.nunique()) . missing_data: Sales 0 dtype: int64 unique dates: 18 . pd.crosstab(index=train.index.year, columns=train.index.quarter) . col_0 1 2 3 4 . row_0 . 2012 1 | 1 | 1 | 1 | . 2013 1 | 1 | 1 | 1 | . 2014 1 | 1 | 1 | 1 | . 2015 1 | 1 | 1 | 1 | . 2016 1 | 1 | 0 | 0 | . Observations: . No null values | Length of the train set is 12 and we have 12 unique dates/quarters so no duplicate dates | Each year and quarter has 1 observation, so no duplicates and data is continuous | #collapse-hide train_chart=alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;Date&#39;, y=&#39;Sales&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]) rolling_mean = alt.Chart(train.reset_index()).mark_trail( color=&#39;orange&#39;, size=1 ).transform_window( rolling_mean=&#39;mean(Sales)&#39;, frame=[-4,4] ).encode( x=&#39;Date:T&#39;, y=&#39;rolling_mean:Q&#39;, size=&#39;Sales&#39; ) (train_chart + rolling_mean).properties(width=800) . . green : #4daa4e 77 170 78 . red: #d6555c rgb(214, 85, 92) . orange: #ff8c0f rgb(255, 161, 40) . blue: #4d6eae rgb(77, 110, 174) . alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;quarter(Date)&#39;, y=&#39;Sales&#39;, column=&#39;year(Date)&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]).properties( width=100) . alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;year(Date)&#39;, y=&#39;Sales&#39;, column=&#39;quarter(Date)&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]).properties( width=100) . Observations: . Sales goes up from Q1 to Q3, peaks in Q3, drops in Q4. Definitely a seasoanl pattern. =&gt; Model should capture seasonality | Just comparing Q4 peaks, sales has gone up from $432K to $582K =&gt; Trend exists, Model should capture trend. No cyclic behaviour | Overall data looks clean and &#39;visually&#39; no outliers or anamolies =&gt; won&#39;t need any data cleaning or filtering | Quarterly / Yearly trends &amp; distrbution . #Quarterly plot: Shows trend for Q1-Q4 for each of the years. Red line shows mean quarter_plot(train); . sns.distplot(train, label=&#39;Train&#39;, hist=False) sns.distplot(train[&#39;2012&#39;], label=&#39;2012&#39;, hist=False) sns.distplot(train[&#39;2013&#39;], label=&#39;2013&#39;, hist=False) sns.distplot(train[&#39;2014&#39;], label=&#39;2014&#39;, hist=False) sns.distplot(train[&#39;2015&#39;], label=&#39;2015&#39;, hist=False); . sns.heatmap(pd.pivot_table(data=train, index=train.index.year, columns=train.index.quarter), square=True, cmap=&#39;Blues&#39;, xticklabels=[&quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;, &quot;Q4&quot;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x18ff0a3d208&gt; . Observations: . Quarter plot &amp; heatmap confirms peak in Q3, drop in Q4. | For each of the years the upward trend observed in all quarters | Kenel Density plot shows somewhat normal distribution, (bi-modal). Peaks shifts from 2012 to 2014 indicating increase in mean. Overall distribution profile is consistent across the years. =&gt; mean centering/scaling likely not needed | 2nd order properties of the time series . #Is the data stationary? train.plot(figsize=(12,8), legend=True, label=&quot;Train&quot;, cmap=&#39;gray&#39;) train[&quot;Sales&quot;].rolling(3).mean().plot(legend=True, label=&quot;Rolling Mean 3Q&quot;); . train[&quot;Sales&quot;].rolling(3).std().plot(legend=True, label=&quot;Rolling Std Deviation 3Q&quot;); . Visually mean and std dev change over time =&gt; Not stationary. . plot_acf(train); plot_pacf(train); . Observations: . ACF: Very interesting. auto-correlation plot shows autocorrelation coeff is insignificant at all lag values (within the blue 95%CI band). Note that coeff sign changed after 4 lags indicating seasonal pattern with seasonal_period=4 (which we already knew since tihs is a quarterly data). Also, alternating pattern shows mean-reversion process. since AC coeff is not significant likley MA(q=0) process | PACF: At lag 1, barely within the 95% CI but significant at lags 5,6,7,8,9,10,11, 12. Significant peak at 8 which is harmonic of 4. Alternating pattern shows seasonal behaviour. Significant peaks show AR process. Differencing would be needed to make the data stationary. =&gt; For ARIMA model ~ ARIMA(1,1,0)?? | #Let&#39;s try differencing d=1 to de-trend the series de_trended = train.diff(1).dropna() de_trended.plot(label=&quot;De-trended&quot;, legend=True) plot_pacf(de_trended); . plot_acf(diff(train, 1,1,4)); plot_pacf(diff(train, 1,1,4)); . Differencing didnot help stationarize the series ! . #Statistical test for stationarity adfuller(train[&quot;Sales&quot;]) . (2.452618859692341, 0.9990329594016152, 7, 10, {&#39;1%&#39;: -4.331573, &#39;5%&#39;: -3.23295, &#39;10%&#39;: -2.7487}, 212.6280742064206) . p = 0.99 which is &gt;0.05. Time series is not stationary . #Shapiri-Wilcox test for normality. if p&lt; 0.05, data is normal sm.stats.diagnostic.kstest_normal(train[&quot;Sales&quot;],&quot;norm&quot;)[1] . 0.7165057864636755 . Series is not normally distributed . De-trended series, ACF/PACF plots show seasonality=4 since this is a quarterly data. I am going to try Power Spectrum analysis to see if there are any other frequencies/signals . Summary: What do I know so far? . Trend &amp; seasonality present. My guess trend=additive, seasonal =&quot;add/mul&quot;, seasonal_periods=4, no damping, since differencing didnot help, highly non-stationary, ETS residual may be non-normal | Normally distributed, boxcox, log, scaling transofmration likley not needed | No outliers to treat | Likley AR process with high order differencing for SARIMA | anderson(train[&quot;Sales&quot;]).statistic . 0.29859509940060747 . ETS Model . Decompose the series into trend, season and resid. Goals: . Is the trend linear, linear exponential, damped | Seasonality? | Are the residuals normal? If the residuals are not normal, point-forecasts will still be accurate but the prediction intervals wont be. Bootstrapping maybe needed | decompose = seasonal_decompose(train) decompose.plot(); . f, fx = signal.periodogram(decompose.seasonal.values) freq=f.reshape(len(f),1) #reshape the array to a column amplitude = fx.reshape(len(f),1) plt.plot(1/freq, amplitude ); . Power Spectral analysis shows a peak at 4 =&gt; seasonality =4 . fig, ax = plt.subplots(sharex=True, sharey=True) train.plot(legend=True, label=&quot;Train&quot;, sharex=True, ax=ax) decompose.trend.plot(legend=True, label=&quot;Train&quot;,ax=ax) plt.figure(figsize=(12,9)) plt.show() . &lt;Figure size 864x648 with 0 Axes&gt; . Trend does look exponential. Do we need boxcox? may be not but worth trying. . #Distribution of the residual. Not normal. be sure to run diagnostics on the fitted model&#39;s residuals decompose.resid.hist(); . Grid-searching ETS model . Grid Searching the parameter space . model_ses = SimpleExpSmoothing(train[&quot;Sales&quot;]).fit() model1=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit() model2=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit() model3=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;mul&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit() model4=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;mul&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit() model5=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit(use_boxcox=True) model6=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit(use_boxcox=True) print(&quot;Train RMSE, MAPE:&quot;, &quot; n SES: &quot;, rmse(train[&quot;Sales&quot;],model_ses.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model_ses.fittedvalues), &quot; n model1:&quot;, rmse(train[&quot;Sales&quot;],model1.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model1.fittedvalues), &quot; n model2:&quot;, rmse(train[&quot;Sales&quot;],model2.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model2.fittedvalues), &quot; n model3:&quot;, rmse(train[&quot;Sales&quot;],model3.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model3.fittedvalues), &quot; n model4:&quot;, rmse(train[&quot;Sales&quot;],model4.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model4.fittedvalues), &quot; n model5:&quot;, rmse(train[&quot;Sales&quot;],model5.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model5.fittedvalues), &quot; n model6:&quot;, rmse(train[&quot;Sales&quot;],model6.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model6.fittedvalues), ) . Train RMSE, MAPE: SES: 67196.83727676631 , 11.737847424882816 model1: 18169.415979095116 , 2.421781848260075 model2: 15131.10006066934 , 2.1284667721448605 model3: 19709.0984764635 , 2.9819826581436972 model4: 12248.838186205909 , 2.311953374582752 model5: 15390.048459667778 , 2.2660607344163934 model6: 15473.587112631554 , 2.2844527000583903 . accuracy(train[&quot;Sales&quot;],model6.fittedvalues) . %MAPE RMSE . 0 2.3 | 15473.6 | . Residual Check . Check the residuals. Run Ljung Box test for white noise and see if residuals are uncorrelated. For lags use: . Seasonal min(2m, T/5), non-seasonal: (10,T/5) -- https://robjhyndman.com/hyndsight/ljung-box-test/ . Residuals should be: . Uncorrelated (Ljung Box) | Zero mean (Ljung Box) | Constant variance (for prediction interval) | Normal (for prediction interval) | residcheck(model1.resid, 10); . ** Mean of the residuals: 4937.902751839591 ** Ljung Box Test, p-value: 0.5197061335692237 (&gt;0.05, Uncorrelated) ** A-D Normality Test, p_value: 1.2654780573669022 (&gt;0.05, Not-normal) ** AD Fuller, p_value: 0.0012050606212250445 (&lt;0.05, Stationary) . sm.stats.diagnostic.kstest_normal(model1.resid,&quot;norm&quot;)[1] . 0.005477051755401487 . train.plot(legend=True, label=&quot;Sales Data&quot;, figsize=(12,8), cmap=&#39;gray&#39;, style=&#39;--&#39;) model2.predict(1, len(train)).plot(legend=True, label=&quot;without log&quot;) model6.predict(1, len(train)).plot(legend=True, label=&quot;log&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x184f7e1d898&gt; . #data.plot(legend=True, label=&quot;Sales Data&quot;, figsize=(20,8), cmap=&#39;gray&#39;, style=&#39;--&#39;) test.plot(legend=True, label=&quot;Test&quot;, figsize=(20,8), style=&#39;--&#39;) model2.predict(1, len(data)+6).plot(legend=True, label=&quot;without log&quot;) model6.predict(1, len(data)+6).plot(legend=True, label=&quot;log&quot;) model1.predict(1, len(data)+6).plot(legend=True, label=&quot;add&quot;) model3.predict(1, len(data)+6).plot(legend=True, label=&quot;model3&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x184f7d99780&gt; . %%R -i train -o ets_summary library(fpp2) r_train &lt;- ts(train$Sales, start=c(2012,03,31), frequency=4) ets_summary &lt;- r_train %&gt;% ets() . #Using tsCV . %%R -i data -o mean_e,mean_e2,mean_e3,mean_e_arima,mean_e_arima_box,lam r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) lam &lt;- BoxCox.lambda(r_data) fets1 &lt;- function(x, h) { forecast(ets(x), h = h) } e &lt;- tsCV(r_data, fets, h=1) mean_e=mean(e^2, na.rm=TRUE) #with log fets2 &lt;- function(x, h) { forecast(ets(x, lambda=0), h = h) } e_log &lt;- tsCV(r_data, fets2, h=1) mean_e2=mean(e_log^2, na.rm=TRUE) #with BoxCox fets3 &lt;- function(x, h) { forecast(ets(x, lambda=lam), h = h) } e_box &lt;- tsCV(r_data, fets3, h=1) mean_e3=mean(e_box^2, na.rm=TRUE) #with ARIMA farima &lt;- function(x, h) { forecast(auto.arima(x), h = h) } e_arima &lt;- tsCV(r_data, farima, h=1) mean_e_arima=mean(e_arima^2, na.rm=TRUE) #with ARIMA &amp; BoxCox farima_box &lt;- function(x, h) { forecast(auto.arima(x, lambda=lam), h = h) } e_arima2 &lt;- tsCV(r_data, farima_box, h=1) mean_e_arima_box=mean(e_arima2^2, na.rm=TRUE) . %%R -i data -o mean_e_MAM,mean_e_AAA,mean_e2 r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) lam &lt;- BoxCox.lambda(r_data) fets_MAM &lt;- function(x, h) { forecast(ets(x, model=&#39;MAM&#39;), h = h) } e_MAM &lt;- tsCV(r_data, fets_MAM, h=1) mean_e_MAM=mean(e_MAM^2, na.rm=TRUE) fets_AAA &lt;- function(x, h) { forecast(ets(x, model=&#39;AAA&#39;), h = h) } e_AAA &lt;- tsCV(r_data, fets_AAA, h=1) mean_e_AAA=mean(e_AAA^2, na.rm=TRUE) #with log fets_MAM_log &lt;- function(x, h) { forecast(ets(x,model=&#39;MAM&#39;, lambda=lam), h = h) } e_log &lt;- tsCV(r_data, fets_MAM_log, h=1) mean_e2=mean(e_log^2, na.rm=TRUE) . print(mean_e_MAM,mean_e_AAA,mean_e2, end=&quot;&quot;) . [1] 2413822041 [1] 2736208289 [1] NaN . %%R -i data -o ets_summary2 library(fpp2) r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) ets_summary2 &lt;- r_data %&gt;% ets() . print(ets_summary) . ETS(M,A,M) Call: ets(y = .) Smoothing parameters: alpha = 0.8309 beta = 0.0055 gamma = 1e-04 Initial states: l = 338029.7256 b = 17199.4484 s = 0.8732 1.1323 1.0171 0.9773 sigma: 0.0411 AIC AICc BIC 415.7237 438.2237 423.7370 . model2.summary() . ExponentialSmoothing Model Results Dep. Variable: endog | No. Observations: 18 | . Model: ExponentialSmoothing | SSE 4121103402.828 | . Optimized: True | AIC 362.482 | . Trend: Additive | BIC 369.605 | . Seasonal: Multiplicative | AICC 393.911 | . Seasonal Periods: 4 | Date: Thu, 19 Mar 2020 | . Box-Cox: False | Time: 19:10:57 | . Box-Cox Coeff.: None | | . | coeff code optimized . smoothing_level 0.5789474 | alpha | True | . smoothing_slope 0.5789474 | beta | True | . smoothing_seasonal 0.1052632 | gamma | True | . initial_level 4.778e+05 | l.0 | True | . initial_slope 9750.0000 | b.0 | True | . initial_seasons.0 0.7712350 | s.0 | True | . initial_seasons.1 0.8109963 | s.1 | True | . initial_seasons.2 0.8992978 | s.2 | True | . initial_seasons.3 0.6952976 | s.3 | True | . %%R install.packages(&#39;dplyr&#39;) . data.tail() . Sales . Date . 2016-12-31 592000 | . 2017-03-31 627000 | . 2017-06-30 725000 | . 2017-09-30 854000 | . 2017-12-31 661000 | . data.head() . Sales . Date . 2012-03-31 362000 | . 2012-06-30 385000 | . 2012-09-30 432000 | . 2012-12-31 341000 | . 2013-03-31 382000 | . %R install.packages(&quot;rlang&quot;) . source = data.reset_index() . source = data.reset_index() rolling = source[&quot;Sales&quot;].rolling(3).mean() . base = alt.Chart(source).encode(x=&#39;Date&#39;) data = base.mark_line().encode(y=&quot;Sales&quot;) roll = alt.Chart(rolling).encode(x=&#39;Date&#39;, y=&#39;Sales&#39;) . alt.Chart(source).transform_density( &#39;Sales&#39;, as_=[&#39;Sales&#39;, &#39;density&#39;], extent = [0,1200] ).mark_area().encode( x=&quot;Sales:Q&quot;, y=&#39;density:Q&#39;, ) .",
            "url": "https://pawarbi.github.io/blog/forecasting/r/python/rpy2/2020/03/30/timeseries.html",
            "relUrl": "/forecasting/r/python/rpy2/2020/03/30/timeseries.html",
            "date": " â€¢ Mar 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Time series Forecasting in Python & R",
            "content": "Project Goals . This is a quarterly sales data of a French retail company from Prof. Rob Hyndman&#39;s &quot;Forecasting Methods &amp; Applications&quot; book. I have uploaded the data to my github. I chose this example because it&#39;s deceptively simple, easy to explain/demonstrate key concepts and Prof. Hyndman later applied the state space approach to this series using family of ETS models. The goals for this project are: . Forecast 1 year ahead , i.e next 4 quarters | Create a forecast pipeline using Python first &amp; later R for comparison purposes | Compare various forecasting methods &amp; choose the best model. Evaluate the models using various evaluation criteria. | Focus on explanability and identify how EDA informs the model selection | Dcoument my findings &amp; notes to self | Importing libraries . #Author: Sandeep Pawar #Version: 1.0 #Date Mar 27, 2020 import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import scipy from scipy.stats import anderson from statsmodels.tools.eval_measures import rmse from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot from statsmodels.tsa.seasonal import seasonal_decompose from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing from statsmodels.stats.diagnostic import acorr_ljungbox as ljung #from nimbusml.timeseries import SsaForecaster from statsmodels.tsa.statespace.tools import diff as diff import statsmodels.api as sm import altair as alt import itertools #import gluonts import pmdarima as pm from pmdarima import ARIMA, auto_arima from scipy import signal from scipy.stats import shapiro from scipy.stats import boxcox %matplotlib inline import warnings warnings.filterwarnings(&quot;ignore&quot;) import rpy2 from rpy2.robjects import pandas2ri pandas2ri.activate() %load_ext rpy2.ipython . I have found that results could be significanlty different if you use different version of the libraries, especially with statsmodels &amp; rpy2. So if you want to reproduce these results, be sure to use the same versions of these libraries. For this project, I created a conda virtual environment as rpy2 requires specific versions of Pandas &amp; certain R libraries . #Printing library versions print(&#39;Pandas:&#39;, pd.__version__) print(&#39;Statsmodels:&#39;, sm.__version__) print(&#39;Scipy:&#39;, scipy.__version__) print(&#39;Rpy2:&#39;, rpy2.__version__) . Pandas: 0.25.0 Statsmodels: 0.11.0 Scipy: 1.4.1 Rpy2: 2.9.4 . # Define some custom functions to help the analysis def MAPE(y_true, y_pred): &quot;&quot;&quot; %Error compares true value with predicted value. Lower the better. Use this along with rmse(). If the series has outliers, compare/select model using MAPE instead of rmse() &quot;&quot;&quot; y_true, y_pred = np.array(y_true), np.array(y_pred) return np.mean(np.abs((y_true - y_pred) / y_true)) * 100 def residcheck(residuals, lags): &quot;&quot;&quot; Function to check if the residuals are white noise. Ideally the residuals should be uncorrelated, zero mean, constant variance and normally distributed. First two are must, while last two are good to have. If the first two are not met, we have not fully captured the information from the data for prediction. Consider different model and/or add exogenous variable. If Ljung Box test shows p&gt; 0.05, the residuals as a group are white noise. Some lags might still be significant. Lags should be min(2*seasonal_period, T/5) from scipy.stats import anderson https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html anderson().statistic &lt;0.05 =&gt; Normal distribution plots from: https://tomaugspurger.github.io/modern-7-timeseries.html &quot;&quot;&quot; resid_mean = np.mean(residuals) lj_p_val = min(ljung(x=residuals, lags=lags)[1]) norm_p_val = anderson(residuals, dist=&#39;norm&#39;).statistic adfuller_p = adfuller(residuals)[1] fig = plt.figure(figsize=(10,8)) layout = (2, 2) ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2); acf_ax = plt.subplot2grid(layout, (1, 0)); kde_ax = plt.subplot2grid(layout, (1, 1)); residuals.plot(ax=ts_ax) plot_acf(residuals, lags=lags, ax=acf_ax); sns.kdeplot(residuals); #[ax.set_xlim(1.5) for ax in [acf_ax, kde_ax]] sns.despine() plt.tight_layout(); print(&quot;** Mean of the residuals: &quot;, resid_mean) print(&quot; n** Ljung Box Test, p-value:&quot;, lj_p_val, &quot;(&gt;0.05, Uncorrelated)&quot; if (lj_p_val &gt; 0.05) else &quot;(&lt;0.05, Correlated)&quot;) print(&quot; n** A-D Normality Test, p_value:&quot;, norm_p_val, &quot;(&lt;0.05, Normal)&quot; if (norm_p_val&lt;0.05) else &quot;(&gt;0.05, Not-normal)&quot;) print(&quot; n** AD Fuller, p_value:&quot;, adfuller_p, &quot;(&gt;0.05, Non-stationary)&quot; if (adfuller_p &gt; 0.05) else &quot;(&lt;0.05, Stationary)&quot;) return ts_ax, acf_ax, kde_ax def accuracy(y1,y2): accuracy_df=pd.DataFrame() rms_error = np.round(rmse(y1, y2),1) map_error = np.round(np.mean(np.abs((np.array(y1) - np.array(y2)) / np.array(y1))) * 100,1) accuracy_df=accuracy_df.append({&quot;RMSE&quot;:rms_error, &quot;%MAPE&quot;: map_error}, ignore_index=True) return accuracy_df . Importing Data . path = &#39;https://raw.githubusercontent.com/pawarbi/datasets/master/timeseries/ts_frenchretail.csv&#39; #Sales numbers are in thousands, so I am dividing by 1000 to make it easier to work with numbers, especially squared errors data = pd.read_csv(path, parse_dates=True, index_col=&quot;Date&quot;).div(1000) data.index.freq=&#39;Q&#39; data.head() . Sales . Date . 2012-03-31 362.0 | . 2012-06-30 385.0 | . 2012-09-30 432.0 | . 2012-12-31 341.0 | . 2013-03-31 382.0 | . I have explicitly set the index frequency to quarterly. This makes with plotting and analyzing data with pandas plotting easier. More date offsets can be found in Pandas documentation here. freq=&#39;Q-DEC&#39; below shows quarterly data ending in December. Other advantage of setting the &#39;freq&#39; value is that if the dates are not continous, Pandas will throw an error, which can be used to fix the data quality error and make the series continuos. Other common date offsets are: . Monthly Start: &#39;MS&#39; | Quarterly Start: &#39;QS&#39; | Weekly: &#39;W&#39; | Bi Weekly: &#39;2W&#39; | Business/ Weekday: &#39;B | Hourly: &#39;H&#39; | . data.index . DatetimeIndex([&#39;2012-03-31&#39;, &#39;2012-06-30&#39;, &#39;2012-09-30&#39;, &#39;2012-12-31&#39;, &#39;2013-03-31&#39;, &#39;2013-06-30&#39;, &#39;2013-09-30&#39;, &#39;2013-12-31&#39;, &#39;2014-03-31&#39;, &#39;2014-06-30&#39;, &#39;2014-09-30&#39;, &#39;2014-12-31&#39;, &#39;2015-03-31&#39;, &#39;2015-06-30&#39;, &#39;2015-09-30&#39;, &#39;2015-12-31&#39;, &#39;2016-03-31&#39;, &#39;2016-06-30&#39;, &#39;2016-09-30&#39;, &#39;2016-12-31&#39;, &#39;2017-03-31&#39;, &#39;2017-06-30&#39;, &#39;2017-09-30&#39;, &#39;2017-12-31&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;Date&#39;, freq=&#39;Q-DEC&#39;) . Train Test Split: . Before analyzing the data, first split it into train and test(hold-out) for model evaluation. All the EDA and model fitting/selection should be done first using train data. DON&#39;T look at test sample until later to avoid any bias. In this case we want to forecast 4 quarters into the future so test size should be at least 4 or more. I will use last 6 samples as hold-out. Note that in this case I am always selecting the last 6 values for test by using .iloc[:-6]. As we get more data, this will ensure that last 6 values are always for validation. Unlike typical train/test split, we can not shuffle the data before splitting. . Cross-validation: . Data can be split using above method or using cross-validation where the series is split into number of successive segments and model is tested using one-step ahead forecast.Model accuracy in that case is based on mean of the cross-validation errors over the number of splits used. This minimizes chances of overfitting. Be sure include at least 1-2 seasonal periods to capture the seasonality. e.g. in this case, the first training set of the CV should be min 8 values so the model has captured seasonal behaviour from 2 years. This is the preferred method when the time series is short. . In this example, the series has 24 obervations so I can use last 6-8 for validation. When this method is used, always check the sensisitivity of the model performance and model parameters to train/test size. If AIC or AICc is used for model evaluation, it approximatley approaches cross-validation error asymptotically. . Insert picture here of train/test split . train = data.iloc[:-6] test = data.iloc[-6:] #forecast horizon h = 6 train_length = len(train) print(&#39;train_length:&#39;,train_length, &#39; n test_length:&#39;, len(test) ) . train_length: 18 test_length: 6 . Exploratory Data Analysis &amp; Modeling Implications . These are some of the questions I ask at various stages of model building. . Are there any null values? how many? best way to impute the null data? If null/NaNs are present, first identify why the data is missing and if NaNs mean anything. Missing values can be filled by interpolation, forward-fill or backward-fill depending on the data nd context. Also make sure null doesnt mean 0, which is acceptable but has modeling implications. | . | Are the data/dates continuous? In this exmaple I am only looking at continous time-series. There other methods that deal with non-continuous data. ETS &amp; ARIMA require the data to be continuous. | . | Are there any duplicate dates, data? Remove the duplicates or aggregate the data (e.g. average or mean) to treat duplicates | . | Any &#39;potential&#39; outliers? . Outliers are defined as observations that differ significantly from the general observations. Identify if the data is susceptible to outliers/spikes, if outliers mean anything and how to define outliers. While &#39;Outlier Detection&#39; is a topic in itself, in forecasting context we want to treat outliers before the data is used for fitting the model. Both ETS and ARIMA class of models (especially ARIMA) are not robust to outliers and can provide erroneous forecasts. Data should be analyzed while keeping seasonality in mind. e.g. a sudden spike could be because of the seasonal behaviour. . | Few ways to treat outliers: . Use Box and whiskers and clip the values tha exceed 1 &amp; 99th percentile | Use residual standard deviation and compare against observed values | Use moving average to check spikes/troughs | . | Another important reason to pay close attention to outliers is that we will choose the appropriate error metric based on that. There are many error metrics used to assess accuracy of forecasts, viz. MAE, MSE, RMSE, %MAPE, %sMAPE. If outliers are present, don&#39;t use RMSE because the squaring the error at the outlier value can inflate the RMSE. In that case model should be selected/assessed using %MAPE or %sMAPE. More on that later. . | . | Visually any trend, seasonality, cyclic behaviour? This will help us choose the appropriate model (Single, Double, Triple Exponential Smoothing, ARIMA/SARIMA) | If cyclic behiour is present (seasonality is short-order variation e.g. month/quarter, cyclicity occurs over 10-20 years e.g. recession) we will need to use different type of ETS model (X11, STL). Depending on the context and purpose of analysis, seasoanlity adjustment may also be needed. | If multiple seasonalities are present, ETS or ARIMA cannot be used. SSA, TBATS, harmonic regression are more appropriate in that case. | Frequency of seasonality is importnat. ETS &amp; SARIMAX are nor appropriate for high frequency data such as hourly, daily, sub-daily and even weekly. Consider using SSA,TBTAS, FB Prophet, deep learning models. | . | How does the data change from season to season for each year? Does it increas/decrease with the trend? Changes slowly, rapidly or remains constant. This is an important observation to be made, especially for ETS model, as it can determine the parametrs to be used &amp; if any preprocessing will be needed. | . | 7. How does the data change from year to year? . Distribution of the data? will we need any transformations? While normally distributed data is not a requirement for forecasting and doesnt necessarily improve point forecast accuracy, it can help stablize the variance and narrow the prediction interval. | Plot the histogram/KDE for each time period (e.g. each year and each seasona) to get gauge peakedness, spread in the data. It can also help compare different periods and track trends over time. | If the data is severely skewed, consider normalizing the data before training the model. Be sure to apply inverse transformation on the forecasts. Use the same transformation parameters on the train and test sets. Stabilizing the variance by using Box Cox transformation (special case being log &amp; inverse transform), power law etc can help more than normalizing the data. | Watch out for outliers before transformation as it will affect the transformation | Plottng distribution also helps track &quot;concept-drift&quot; in the data, i.e. does the underlying temporal structure / assumption change over time. If the drift is significant, refit the model or at least re-evaluate. This can be tricky in time series analysis. | Uncertainty in the training data will lead to higher uncertainty in the forecast. If the data is highly volatile/uncertain (seen by spread in the distribution, standard deviation, non-constant variance etc), ETS and ARIMA models will not be suitable. Consider GARCH and other methods. | . | Is the data stationary? Is this a white noise, random walk process? . Perhaps the most important concept to keep in mind when doing time series analysis and forecasting is that, time series is a probabilistic / stochastic process, and the time series we are analyzing is a &#39;realization of a stochastic process&#39;. A time signal could be deterministic or stochastic/probabilistic. In a deterministic process, the future values can be predicted exactly with a mathematical function e.g. y = sin(2$ pi$ft). In our case, the future values can only be expressed in terms of probability distribution. The point estimates are mean/median of the distribution. By definition, the mean has a distribution around it and as such the stakeholders should be made aware of the probabilistic nature of the forecast through uncertainty estimates. . | Stationarity: Statistical stationarity means the time series has constant mean, variance and autocorrelation is insignificant at all lags. Autocorrelation is a mouthful, all it means is the correlation with its past self. e.g. to check if two variables are linearly correlated with each other, we calculate their coeff of correlation (Pearson correlation). Similarly, autocorrelation does the same thing but with its past values (i.e lags). More on that later. For a stationary time series, the properties are the same no matter which part of the series (w.r.t time) we look at. This is a core concept of the ARIMA methods, as only sttaionary processes can be modeled using ARIMA. ETS can handle non-stationary processes. . | White Noise: If a time series has zero mean and a constant variance $ sigma^2$, it&#39;s a white noise. The variables in this case are independent and identically distributed (i.i.d) and are uncorrelated. We want the residuals left after fitting the model to be a white noise. White noise can be identified by using ADFuller test and plotting autocorrelation function (ACF) plots. | Random Walk: Random walks are non-stationary. It&#39;s mean or variance or both changes over time. Random walk cannot be forecast because we have more unknowns than the data so we will end up having way to many parameters in the model. In essence, random walk has no pattern to it, it&#39;s last data point plus some random signal (drift). Thus, if the first difference of the time series results in a white noise, it&#39;s an indication of a Random Walk. Most equity stocks are random walk but by looking at percent difference (%growth over time) we can study the white noise. | . | Next data point = Last Data point + Random Noise =&gt; Next Data Point - Last Data Point = Random Noise (i.e White noise) - . Auto-correlation? at what lag? | If trend is present, momentum or mean-reversing? | Break-points in the series? | Intermittent demand? | #Any missing data? print(&quot;missing_data:&quot;, train.isna().sum()) print(&quot;unique dates:&quot;, train.index.nunique()) . missing_data: Sales 0 dtype: int64 unique dates: 18 . pd.date_range() . pd.crosstab(index=train.index.year, columns=train.index.quarter) . col_0 1 2 3 4 . row_0 . 2012 1 | 1 | 1 | 1 | . 2013 1 | 1 | 1 | 1 | . 2014 1 | 1 | 1 | 1 | . 2015 1 | 1 | 1 | 1 | . 2016 1 | 1 | 0 | 0 | . Observations: . No null values | Length of the train set is 12 and we have 12 unique dates/quarters so no duplicate dates | Each year and quarter has 1 observation, so no duplicates and data is continuous | train_chart=alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;Date&#39;, y=&#39;Sales&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]) rolling_mean = alt.Chart(train.reset_index()).mark_trail( color=&#39;orange&#39;, size=1 ).transform_window( rolling_mean=&#39;mean(Sales)&#39;, frame=[-4,4] ).encode( x=&#39;Date:T&#39;, y=&#39;rolling_mean:Q&#39;, size=&#39;Sales&#39; ) (train_chart + rolling_mean).properties(width=800) . green : #4daa4e 77 170 78 . red: #d6555c rgb(214, 85, 92) . orange: #ff8c0f rgb(255, 161, 40) . blue: #4d6eae rgb(77, 110, 174) . alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;quarter(Date)&#39;, y=&#39;Sales&#39;, column=&#39;year(Date)&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]).properties( width=100) . alt.Chart(train.reset_index()).mark_line(point=True).encode( x=&#39;year(Date)&#39;, y=&#39;Sales&#39;, column=&#39;quarter(Date)&#39;, tooltip=[&#39;Date&#39;, &#39;Sales&#39;]).properties( width=100) . Observations: . Sales goes up from Q1 to Q3, peaks in Q3, drops in Q4. Definitely a seasoanl pattern. =&gt; Model should capture seasonality | Just comparing Q4 peaks, sales has gone up from $432K to $582K =&gt; Trend exists, Model should capture trend. No cyclic behaviour | Overall data looks clean and &#39;visually&#39; no outliers or anamolies =&gt; won&#39;t need any data cleaning or filtering | Quarterly / Yearly trends &amp; distrbution . #Quarterly plot: Shows trend for Q1-Q4 for each of the years. Red line shows mean quarter_plot(train); . sns.distplot(train, label=&#39;Train&#39;, hist=False) sns.distplot(train[&#39;2012&#39;], label=&#39;2012&#39;, hist=False) sns.distplot(train[&#39;2013&#39;], label=&#39;2013&#39;, hist=False) sns.distplot(train[&#39;2014&#39;], label=&#39;2014&#39;, hist=False) sns.distplot(train[&#39;2015&#39;], label=&#39;2015&#39;, hist=False); . sns.heatmap(pd.pivot_table(data=train, index=train.index.year, columns=train.index.quarter), square=True, cmap=&#39;Blues&#39;, xticklabels=[&quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;, &quot;Q4&quot;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x18ff0a3d208&gt; . Observations: . Quarter plot &amp; heatmap confirms peak in Q3, drop in Q4. | For each of the years the upward trend observed in all quarters | Kenel Density plot shows somewhat normal distribution, (bi-modal). Peaks shifts from 2012 to 2014 indicating increase in mean. Overall distribution profile is consistent across the years. =&gt; mean centering/scaling likely not needed | 2nd order properties of the time series . #Is the data stationary? train.plot(figsize=(12,8), legend=True, label=&quot;Train&quot;, cmap=&#39;gray&#39;) train[&quot;Sales&quot;].rolling(3).mean().plot(legend=True, label=&quot;Rolling Mean 3Q&quot;); . train[&quot;Sales&quot;].rolling(3).std().plot(legend=True, label=&quot;Rolling Std Deviation 3Q&quot;); . Visually mean and std dev change over time =&gt; Not stationary. . plot_acf(train); plot_pacf(train); . Observations: . ACF: Very interesting. auto-correlation plot shows autocorrelation coeff is insignificant at all lag values (within the blue 95%CI band). Note that coeff sign changed after 4 lags indicating seasonal pattern with seasonal_period=4 (which we already knew since tihs is a quarterly data). Also, alternating pattern shows mean-reversion process. since AC coeff is not significant likley MA(q=0) process | PACF: At lag 1, barely within the 95% CI but significant at lags 5,6,7,8,9,10,11, 12. Significant peak at 8 which is harmonic of 4. Alternating pattern shows seasonal behaviour. Significant peaks show AR process. Differencing would be needed to make the data stationary. =&gt; For ARIMA model ~ ARIMA(1,1,0)?? | #Let&#39;s try differencing d=1 to de-trend the series de_trended = train.diff(1).dropna() de_trended.plot(label=&quot;De-trended&quot;, legend=True) plot_pacf(de_trended); . plot_acf(diff(train, 1,1,4)); plot_pacf(diff(train, 1,1,4)); . Differencing didnot help stationarize the series ! . #Statistical test for stationarity adfuller(train[&quot;Sales&quot;]) . (2.452618859692341, 0.9990329594016152, 7, 10, {&#39;1%&#39;: -4.331573, &#39;5%&#39;: -3.23295, &#39;10%&#39;: -2.7487}, 212.6280742064206) . p = 0.99 which is &gt;0.05. Time series is not stationary . #Shapiri-Wilcox test for normality. if p&lt; 0.05, data is normal sm.stats.diagnostic.kstest_normal(train[&quot;Sales&quot;],&quot;norm&quot;)[1] . 0.7165057864636755 . Series is not normally distributed . De-trended series, ACF/PACF plots show seasonality=4 since this is a quarterly data. I am going to try Power Spectrum analysis to see if there are any other frequencies/signals . Summary: What do I know so far? . Trend &amp; seasonality present. My guess trend=additive, seasonal =&quot;add/mul&quot;, seasonal_periods=4, no damping, since differencing didnot help, highly non-stationary, ETS residual may be non-normal | Normally distributed, boxcox, log, scaling transofmration likley not needed | No outliers to treat | Likley AR process with high order differencing for SARIMA | anderson(train[&quot;Sales&quot;]).statistic . 0.29859509940060747 . ETS Model . Decompose the series into trend, season and resid. Goals: . Is the trend linear, linear exponential, damped | Seasonality? | Are the residuals normal? If the residuals are not normal, point-forecasts will still be accurate but the prediction intervals wont be. Bootstrapping maybe needed | decompose = seasonal_decompose(train) decompose.plot(); . f, fx = signal.periodogram(decompose.seasonal.values) freq=f.reshape(len(f),1) #reshape the array to a column amplitude = fx.reshape(len(f),1) plt.plot(1/freq, amplitude ); . Power Spectral analysis shows a peak at 4 =&gt; seasonality =4 . fig, ax = plt.subplots(sharex=True, sharey=True) train.plot(legend=True, label=&quot;Train&quot;, sharex=True, ax=ax) decompose.trend.plot(legend=True, label=&quot;Train&quot;,ax=ax) plt.figure(figsize=(12,9)) plt.show() . &lt;Figure size 864x648 with 0 Axes&gt; . Trend does look exponential. Do we need boxcox? may be not but worth trying. . #Distribution of the residual. Not normal. be sure to run diagnostics on the fitted model&#39;s residuals decompose.resid.hist(); . Grid-searching ETS model . Grid Searching the parameter space . model_ses = SimpleExpSmoothing(train[&quot;Sales&quot;]).fit() model1=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit() model2=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit() model3=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;mul&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit() model4=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;mul&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit() model5=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;add&quot;, seasonal_periods=4).fit(use_boxcox=True) model6=ExponentialSmoothing(train[&quot;Sales&quot;], trend=&quot;add&quot;, damped=False, seasonal=&quot;mul&quot;, seasonal_periods=4).fit(use_boxcox=True) print(&quot;Train RMSE, MAPE:&quot;, &quot; n SES: &quot;, rmse(train[&quot;Sales&quot;],model_ses.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model_ses.fittedvalues), &quot; n model1:&quot;, rmse(train[&quot;Sales&quot;],model1.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model1.fittedvalues), &quot; n model2:&quot;, rmse(train[&quot;Sales&quot;],model2.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model2.fittedvalues), &quot; n model3:&quot;, rmse(train[&quot;Sales&quot;],model3.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model3.fittedvalues), &quot; n model4:&quot;, rmse(train[&quot;Sales&quot;],model4.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model4.fittedvalues), &quot; n model5:&quot;, rmse(train[&quot;Sales&quot;],model5.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model5.fittedvalues), &quot; n model6:&quot;, rmse(train[&quot;Sales&quot;],model6.fittedvalues),&quot; , &quot;, MAPE(train[&quot;Sales&quot;],model6.fittedvalues), ) . Train RMSE, MAPE: SES: 67196.83727676631 , 11.737847424882816 model1: 18169.415979095116 , 2.421781848260075 model2: 15131.10006066934 , 2.1284667721448605 model3: 19709.0984764635 , 2.9819826581436972 model4: 12248.838186205909 , 2.311953374582752 model5: 15390.048459667778 , 2.2660607344163934 model6: 15473.587112631554 , 2.2844527000583903 . accuracy(train[&quot;Sales&quot;],model6.fittedvalues) . %MAPE RMSE . 0 2.3 | 15473.6 | . Residual Check . Check the residuals. Run Ljung Box test for white noise and see if residuals are uncorrelated. For lags use: . Seasonal min(2m, T/5), non-seasonal: (10,T/5) -- https://robjhyndman.com/hyndsight/ljung-box-test/ . Residuals should be: . Uncorrelated (Ljung Box) | Zero mean (Ljung Box) | Constant variance (for prediction interval) | Normal (for prediction interval) | residcheck(model1.resid, 10); . ** Mean of the residuals: 4937.902751839591 ** Ljung Box Test, p-value: 0.5197061335692237 (&gt;0.05, Uncorrelated) ** A-D Normality Test, p_value: 1.2654780573669022 (&gt;0.05, Not-normal) ** AD Fuller, p_value: 0.0012050606212250445 (&lt;0.05, Stationary) . sm.stats.diagnostic.kstest_normal(model1.resid,&quot;norm&quot;)[1] . 0.005477051755401487 . train.plot(legend=True, label=&quot;Sales Data&quot;, figsize=(12,8), cmap=&#39;gray&#39;, style=&#39;--&#39;) model2.predict(1, len(train)).plot(legend=True, label=&quot;without log&quot;) model6.predict(1, len(train)).plot(legend=True, label=&quot;log&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x184f7e1d898&gt; . #data.plot(legend=True, label=&quot;Sales Data&quot;, figsize=(20,8), cmap=&#39;gray&#39;, style=&#39;--&#39;) test.plot(legend=True, label=&quot;Test&quot;, figsize=(20,8), style=&#39;--&#39;) model2.predict(1, len(data)+6).plot(legend=True, label=&quot;without log&quot;) model6.predict(1, len(data)+6).plot(legend=True, label=&quot;log&quot;) model1.predict(1, len(data)+6).plot(legend=True, label=&quot;add&quot;) model3.predict(1, len(data)+6).plot(legend=True, label=&quot;model3&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x184f7d99780&gt; . %%R -i train -o ets_summary library(fpp2) r_train &lt;- ts(train$Sales, start=c(2012,03,31), frequency=4) ets_summary &lt;- r_train %&gt;% ets() . #Using tsCV . %%R -i data -o mean_e,mean_e2,mean_e3,mean_e_arima,mean_e_arima_box,lam r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) lam &lt;- BoxCox.lambda(r_data) fets1 &lt;- function(x, h) { forecast(ets(x), h = h) } e &lt;- tsCV(r_data, fets, h=1) mean_e=mean(e^2, na.rm=TRUE) #with log fets2 &lt;- function(x, h) { forecast(ets(x, lambda=0), h = h) } e_log &lt;- tsCV(r_data, fets2, h=1) mean_e2=mean(e_log^2, na.rm=TRUE) #with BoxCox fets3 &lt;- function(x, h) { forecast(ets(x, lambda=lam), h = h) } e_box &lt;- tsCV(r_data, fets3, h=1) mean_e3=mean(e_box^2, na.rm=TRUE) #with ARIMA farima &lt;- function(x, h) { forecast(auto.arima(x), h = h) } e_arima &lt;- tsCV(r_data, farima, h=1) mean_e_arima=mean(e_arima^2, na.rm=TRUE) #with ARIMA &amp; BoxCox farima_box &lt;- function(x, h) { forecast(auto.arima(x, lambda=lam), h = h) } e_arima2 &lt;- tsCV(r_data, farima_box, h=1) mean_e_arima_box=mean(e_arima2^2, na.rm=TRUE) . %%R -i data -o mean_e_MAM,mean_e_AAA,mean_e2 r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) lam &lt;- BoxCox.lambda(r_data) fets_MAM &lt;- function(x, h) { forecast(ets(x, model=&#39;MAM&#39;), h = h) } e_MAM &lt;- tsCV(r_data, fets_MAM, h=1) mean_e_MAM=mean(e_MAM^2, na.rm=TRUE) fets_AAA &lt;- function(x, h) { forecast(ets(x, model=&#39;AAA&#39;), h = h) } e_AAA &lt;- tsCV(r_data, fets_AAA, h=1) mean_e_AAA=mean(e_AAA^2, na.rm=TRUE) #with log fets_MAM_log &lt;- function(x, h) { forecast(ets(x,model=&#39;MAM&#39;, lambda=lam), h = h) } e_log &lt;- tsCV(r_data, fets_MAM_log, h=1) mean_e2=mean(e_log^2, na.rm=TRUE) . print(mean_e_MAM,mean_e_AAA,mean_e2, end=&quot;&quot;) . [1] 2413822041 [1] 2736208289 [1] NaN . %%R -i data -o ets_summary2 library(fpp2) r_data &lt;- ts(data$Sales, start=c(2012,03,31), frequency=4) ets_summary2 &lt;- r_data %&gt;% ets() . print(ets_summary) . ETS(M,A,M) Call: ets(y = .) Smoothing parameters: alpha = 0.8309 beta = 0.0055 gamma = 1e-04 Initial states: l = 338029.7256 b = 17199.4484 s = 0.8732 1.1323 1.0171 0.9773 sigma: 0.0411 AIC AICc BIC 415.7237 438.2237 423.7370 . model2.summary() . ExponentialSmoothing Model Results Dep. Variable: endog | No. Observations: 18 | . Model: ExponentialSmoothing | SSE 4121103402.828 | . Optimized: True | AIC 362.482 | . Trend: Additive | BIC 369.605 | . Seasonal: Multiplicative | AICC 393.911 | . Seasonal Periods: 4 | Date: Thu, 19 Mar 2020 | . Box-Cox: False | Time: 19:10:57 | . Box-Cox Coeff.: None | | . | coeff code optimized . smoothing_level 0.5789474 | alpha | True | . smoothing_slope 0.5789474 | beta | True | . smoothing_seasonal 0.1052632 | gamma | True | . initial_level 4.778e+05 | l.0 | True | . initial_slope 9750.0000 | b.0 | True | . initial_seasons.0 0.7712350 | s.0 | True | . initial_seasons.1 0.8109963 | s.1 | True | . initial_seasons.2 0.8992978 | s.2 | True | . initial_seasons.3 0.6952976 | s.3 | True | . %%R install.packages(&#39;dplyr&#39;) . data.tail() . Sales . Date . 2016-12-31 592000 | . 2017-03-31 627000 | . 2017-06-30 725000 | . 2017-09-30 854000 | . 2017-12-31 661000 | . data.head() . Sales . Date . 2012-03-31 362000 | . 2012-06-30 385000 | . 2012-09-30 432000 | . 2012-12-31 341000 | . 2013-03-31 382000 | . %R install.packages(&quot;rlang&quot;) . source = data.reset_index() . source = data.reset_index() rolling = source[&quot;Sales&quot;].rolling(3).mean() . base = alt.Chart(source).encode(x=&#39;Date&#39;) data = base.mark_line().encode(y=&quot;Sales&quot;) roll = alt.Chart(rolling).encode(x=&#39;Date&#39;, y=&#39;Sales&#39;) . alt.Chart(source).transform_density( &#39;Sales&#39;, as_=[&#39;Sales&#39;, &#39;density&#39;], extent = [0,1200] ).mark_area().encode( x=&quot;Sales:Q&quot;, y=&#39;density:Q&#39;, ) .",
            "url": "https://pawarbi.github.io/blog/forecasting/r/python/rpy2/2020/03/29/timeseries.html",
            "relUrl": "/forecasting/r/python/rpy2/2020/03/29/timeseries.html",
            "date": " â€¢ Mar 29, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Test Test Test",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://pawarbi.github.io/blog/jupyter/2020/03/29/test.html",
            "relUrl": "/jupyter/2020/03/29/test.html",
            "date": " â€¢ Mar 29, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://pawarbi.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " â€¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œlevel 1 headingâ€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Hereâ€™s a footnote 1. Hereâ€™s a horizontal rule: . . Lists . Hereâ€™s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes â€¦andâ€¦ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.Â &#8617; . |",
            "url": "https://pawarbi.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " â€¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Resources",
          "content": "My name is Sandeep Pawar . My LinkedIn is Sandeep Pawar .",
          "url": "https://pawarbi.github.io/blog/resources/",
          "relUrl": "/resources/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "About Me",
          "content": "My name is Sandeep Pawar . My LinkedIn is Sandeep Pawar .",
          "url": "https://pawarbi.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}