{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Power BI Datasets via XMLA Endpoint in Python Jupyter Notebook\n",
    "> In this blog post I show how you can use Python to access datasets published to Power BI service using Python in Jupyter Notebook  \n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [PPU, XMLA, PowerBI_Premium, Premium, Python, Jupyter_Notebook]\n",
    "- hide: false"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power BI recently announced availability of a new license ['Premium Per User'](https://powerbi.microsoft.com/en-us/blog/power-bi-premium-per-user-public-preview-now-available/) which will allow small to medium size companies to access Premium features at a lower price point (as of 12/11/2020 price has not been published) . I was given a priority access to it and have been exploring all the premium features for the last few weeks. One of the key benefits of Premium is the ability to consume published datasets via XMLA endpoint. Instead of me describing it, you can read Microsoft's documentation for detailed description [here](https://docs.microsoft.com/en-us/power-bi/admin/service-premium-connect-tools).   \n",
    "\n",
    "To use XMLA endpoint, you will need to have a Premium workspace and enable the 'XMLA Endpoint' in capacity settings. \n",
    "\n",
    "Capacity Settings > Power BI Premium > Workloads > XMLA Endpoint\n",
    "\n",
    "![image](https://docs.microsoft.com/en-us/power-bi/admin/media/service-premium-connect-tools/xmla-endpoint-enable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog post I will show how to setup connection to the XMLA endpoint and access Power BI datasets & measures within those datasets using Python in a Jupyter notebook. This blog post is written in a Jupyter notebook. I use Jupyter notebooks for data exploration, visualization and building machine learning models. Ability to consume published datasets in a notebook will be immensly helpful to me.   \n",
    "\n",
    "I took inspiration from [David Elderveld's](https://www.linkedin.com/in/davideldersveld/) amazing [4-part blogposts](https://dataveld.com/2020/08/17/jupyter-as-an-external-tool-for-power-bi-desktop-python-part-4/) on *'Jupyter as an External Tool for Power BI Desktop'*. It really opened up lot of options that I didn't know existed, thanks David! I highly encourage you to read all the four posts to learn more about using Python with Power BI. \n",
    "\n",
    "Secondly, none of this would be possible without the `python-ssas` [module](https://github.com/yehoshuadimarsky/python-ssas/) by Josh Dimarsky which enables TOM connection to Analysis Services. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, you will need three things:\n",
    "- install the [pythonnet](https://github.com/pythonnet/pythonnet) library (`pip install pythonnet`)\n",
    "- Make sure you have `Microsoft.AnalysisServices.Tabular.dll` and `Microsoft.AnalysisServices.AdomdClient.dll` dlls. If you use Excel, Power BI, you will most likley already have them. As Josh mentions in his documentation, they are usually installed in `C:\\Windows\\Microsoft.NET\\assembly\\GAC_MSIL`\n",
    "- copy the `ssas_api.py` file from [here](https://github.com/yehoshuadimarsky/python-ssas/blob/master/ssas_api.py) and save it in your Python libraries folder or Jupyter working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ssas_api as ssas\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Premium Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to connect to our Power BI service account & the Premium workspace. You will need to find the workspace connection string URL. It will be in this format `powerbi://api.powerbi.com/v1.0/[tenant name]/[workspace name]`. You can obtain it from your workspace settings (see below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First go to your Premium Workspace and click on Settings. Notice that I have three datasets in this workspace, viz Dataset1, dataset2 and dataset2_2.\n",
    "    \n",
    "![ws_settings](https://raw.githubusercontent.com/pawarbi/blog/master/images/xmla1.jpg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, copy the server address from Workspace Connection:\n",
    "\n",
    "![connection](https://raw.githubusercontent.com/pawarbi/blog/master/images/xmla2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variables for your tenant username and password "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'workspace_connection_from_above'\n",
    "\n",
    "username = 'name@email.com'\n",
    "\n",
    "password = 'password'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup connection string by specifying the server name, username & password. Note that I have left the database name (`db_name`) blank here because I am assuming that we don't know the names of the datasets that are available in this workspace. We will explore the workspace and get a list of all the datasets. If you already know the dataset name, you can enter it between the single quotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1 = ssas.set_conn_string(\n",
    "    server=server,\n",
    "    db_name='',\n",
    "    username=username,\n",
    "    password=password\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for [Tabular Object Model](https://docs.microsoft.com/en-us/analysis-services/tom/introduction-to-the-tabular-object-model-tom-in-analysis-services-amo?view=asallproducts-allversions) (TOM) and setup the TOM server. As long as your username and password are valid, you will connect to your workspace using TOM. If it fails, it means either your credentials are incorrect or you do not have access to the workspace. You will *not* be prompted for interactive authentication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Workspace Successful !\n"
     ]
    }
   ],
   "source": [
    "global System, DataTable, AMO, ADOMD\n",
    "\n",
    "import System\n",
    "from System.Data import DataTable\n",
    "import Microsoft.AnalysisServices.Tabular as TOM\n",
    "import Microsoft.AnalysisServices.AdomdClient as ADOMD\n",
    "\n",
    "try:\n",
    "    TOMServer = TOM.Server()\n",
    "    TOMServer.Connect(conn1)\n",
    "    print(\"Connection to Workspace Successful !\")\n",
    "    \n",
    "except:\n",
    "    print(\"Connection to Workspace Failed\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get a list of all the avaible datasets in this workspace and their metadata such as compatibility level, database id, size in megabytes, creation date and last update date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Compatibility</th>\n",
       "      <th>ID</th>\n",
       "      <th>Size_MB</th>\n",
       "      <th>Created_Date</th>\n",
       "      <th>Last_Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset1</td>\n",
       "      <td>1465</td>\n",
       "      <td>a28e52a8-d6b3-4b5c-8e61-e107fbd52748</td>\n",
       "      <td>1.916094</td>\n",
       "      <td>8/21/2018 3:34:53 PM</td>\n",
       "      <td>12/11/2020 11:24:21 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset2_2</td>\n",
       "      <td>1520</td>\n",
       "      <td>a93244fe-860d-45c2-9d36-b44fb284c54d</td>\n",
       "      <td>0.454222</td>\n",
       "      <td>12/11/2020 10:01:57 AM</td>\n",
       "      <td>12/11/2020 11:20:50 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset_Name Compatibility                                    ID   Size_MB  \\\n",
       "0     Dataset1          1465  a28e52a8-d6b3-4b5c-8e61-e107fbd52748  1.916094   \n",
       "1   dataset2_2          1520  a93244fe-860d-45c2-9d36-b44fb284c54d  0.454222   \n",
       "\n",
       "             Created_Date             Last_Update  \n",
       "0    8/21/2018 3:34:53 PM  12/11/2020 11:24:21 AM  \n",
       "1  12/11/2020 10:01:57 AM  12/11/2020 11:20:50 AM  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame(columns=['Dataset_Name', 'Compatibility', 'ID', 'Size_MB','Created_Date','Last_Update' ])\n",
    "\n",
    "for item in TOMServer.Databases:\n",
    "    \n",
    "          \n",
    "    datasets = datasets.append({'Dataset_Name' :item.Name, \n",
    "                     'Compatibility':item.CompatibilityLevel,\n",
    "                     'Created_Date' :item.CreatedTimestamp,\n",
    "                     'ID'           :item.ID,\n",
    "                     'Last_Update'  :item.LastUpdate,\n",
    "                     'Size_MB'      :(item.EstimatedSize*1e-06)    },\n",
    "                     ignore_index=True)\n",
    "    \n",
    "datasets    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have three datasets in this workspace but I only see 2! The reason is that dataset2 was created by uploading the csv file to the worspace while the other two datasets were published to the workspace from Power BI Desktop. Also note that their compatibility levels are different. Dataset1 was published with the old version of Power BI Desktop with 'Enhanced Metadata' option turned off that's why its compatibility level is not 1520.  Since [September 2020 release](https://docs.microsoft.com/en-us/power-bi/connect-data/desktop-enhanced-dataset-metadata), Power BI Desktop automatically converts the datasets to Enhanced Metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose the dataset we want to connect to. In this case I want to access `dataset2_2`. I will copy the database id from the `ID` column from the above table. Then we will find the names of all the tables that are available in that dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2\n"
     ]
    }
   ],
   "source": [
    "ds = TOMServer.Databases['a93244fe-860d-45c2-9d36-b44fb284c54d']\n",
    "\n",
    "for table in ds.Model.Tables:\n",
    "    print(table.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `dataset2_2` dataset, the only available table is `dataset2`. Let's connect to this table. We will create a new connection string by specifying the `db_name` this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = (ssas.set_conn_string(\n",
    "    server=server,\n",
    "    db_name='dataset2_2',\n",
    "    username = 'name@email.com',\n",
    "    password = 'password'\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write any valid DAX query against this table and get the results back as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset2[vendorID]</th>\n",
       "      <th>dataset2[passengerCount]</th>\n",
       "      <th>dataset2[tripDistance]</th>\n",
       "      <th>dataset2[hour_of_day]</th>\n",
       "      <th>dataset2[day_of_week]</th>\n",
       "      <th>dataset2[day_of_month]</th>\n",
       "      <th>dataset2[month_num]</th>\n",
       "      <th>dataset2[normalizeHolidayName]</th>\n",
       "      <th>dataset2[isPaidTimeOff]</th>\n",
       "      <th>dataset2[snowDepth]</th>\n",
       "      <th>dataset2[precipTime]</th>\n",
       "      <th>dataset2[precipDepth]</th>\n",
       "      <th>dataset2[temperature]</th>\n",
       "      <th>dataset2[totalAmount]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.116071</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.116071</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.78</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.116071</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.26</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.116071</td>\n",
       "      <td>9.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.116071</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset2[vendorID]  dataset2[passengerCount]  dataset2[tripDistance]  \\\n",
       "0                   2                         1                    2.62   \n",
       "1                   2                         1                    0.42   \n",
       "2                   2                         1                    1.78   \n",
       "3                   2                         1                    1.26   \n",
       "4                   2                         1                    2.37   \n",
       "\n",
       "   dataset2[hour_of_day]  dataset2[day_of_week]  dataset2[day_of_month]  \\\n",
       "0                      2                      6                      19   \n",
       "1                     17                      6                      19   \n",
       "2                     18                      6                      19   \n",
       "3                     16                      6                      19   \n",
       "4                     22                      6                      19   \n",
       "\n",
       "   dataset2[month_num] dataset2[normalizeHolidayName] dataset2[isPaidTimeOff]  \\\n",
       "0                    6                           None                   False   \n",
       "1                    6                           None                   False   \n",
       "2                    6                           None                   False   \n",
       "3                    6                           None                   False   \n",
       "4                    6                           None                   False   \n",
       "\n",
       "   dataset2[snowDepth]  dataset2[precipTime]  dataset2[precipDepth]  \\\n",
       "0                  0.0                     1                      0   \n",
       "1                  0.0                     1                      0   \n",
       "2                  0.0                     1                      0   \n",
       "3                  0.0                     1                      0   \n",
       "4                  0.0                     1                      0   \n",
       "\n",
       "   dataset2[temperature]  dataset2[totalAmount]  \n",
       "0              23.116071                  11.80  \n",
       "1              23.116071                   4.30  \n",
       "2              23.116071                  12.96  \n",
       "3              23.116071                   9.36  \n",
       "4              23.116071                  10.80  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dax_string = '''\n",
    "    //Write your DAX Query here\n",
    "    EVALUATE\n",
    "    dataset2\n",
    "    '''\n",
    "\n",
    "df_dataset2 = (ssas\n",
    "               .get_DAX(\n",
    "                   connection_string=conn, \n",
    "                   dax_string=dax_string)\n",
    "               \n",
    "              )\n",
    "\n",
    "df_dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='dataset2[totalAmount]'>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df_dataset2['dataset2[totalAmount]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a list of all the measures and their DAX expressions. As seen below, in this table we have only one measure called `totalAmount average per vendorID` with its DAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalAmount average per vendorID :\n",
      " \n",
      "AVERAGEX(\n",
      "\tKEEPFILTERS(VALUES('dataset2'[vendorID])),\n",
      "\tCALCULATE(SUM('dataset2'[totalAmount]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "table = ds.Model.Tables.Find('dataset2')\n",
    "\n",
    "for measure in table.Measures:\n",
    "    print(measure.Name, \":\\n\", measure.Expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this](https://docs.microsoft.com/en-us/power-bi/admin/service-premium-connect-tools) Microsoft documentation, I was under the impression that only the datasets with Compatibility level 1500 or higher could be accessed via XMLA. That's not the case. `Dataset1` has a compatibility of 1465 and can still be access via XMLA endpoint as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KeyInfluencers_Predictors[Feature Name]</th>\n",
       "      <th>KeyInfluencers_Predictors[Feature Type]</th>\n",
       "      <th>KeyInfluencers_Predictors[Feature Importance]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>col6</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.417869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>col0</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.257106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>col4</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.106939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>col3</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.090845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>col1</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.066334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KeyInfluencers_Predictors[Feature Name]  \\\n",
       "0                                    col6   \n",
       "1                                    col0   \n",
       "2                                    col4   \n",
       "3                                    col3   \n",
       "4                                    col1   \n",
       "\n",
       "  KeyInfluencers_Predictors[Feature Type]  \\\n",
       "0                                 Numeric   \n",
       "1                                 Numeric   \n",
       "2                                 Numeric   \n",
       "3                                 Numeric   \n",
       "4                                 Numeric   \n",
       "\n",
       "   KeyInfluencers_Predictors[Feature Importance]  \n",
       "0                                       0.417869  \n",
       "1                                       0.257106  \n",
       "2                                       0.106939  \n",
       "3                                       0.090845  \n",
       "4                                       0.066334  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn3 = (ssas.set_conn_string(\n",
    "    server=server,\n",
    "    db_name='Dataset1',\n",
    "    username = 'name@email.com',\n",
    "    password = 'password'\n",
    " ))\n",
    "\n",
    "dax_string2 = '''\n",
    "    //Write your DAX Query here\n",
    "    EVALUATE\n",
    "    KeyInfluencers_Predictors\n",
    "    '''\n",
    "\n",
    "df_dataset1 = (ssas\n",
    "               .get_DAX(\n",
    "                   connection_string=conn3, \n",
    "                   dax_string=dax_string2)\n",
    "               \n",
    "              )\n",
    "\n",
    "df_dataset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets in Power BI service can currently be accessed via number of different tools (SSDT, SSMS, PowerShell, Tabular Editor, DAX Studio, ALM Toolkit) which are all database modeling tools. But Data Scientists now can easily access the datasets for exploring the data and building machine learning models in Jupyter Notebook or VSCode using Python.  \n",
    "\n",
    "This method can also be used to export multiple refreshed dataset(s) on a schedule and on demand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still few things I am not sure about and need to explore more. \n",
    "- Can I use service principal, key etc so I don't have to write username/password in my code\n",
    "- How to write back, create dataset using Python and push it to the workspace\n",
    "- Can I create/modify measures?\n",
    "- What are the limitations ? \n",
    "\n",
    "\n",
    "Please feel free to post your comments below or reach out to me if you find any errors or have suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "- https://dataveld.com/2020/07/20/python-as-an-external-tool-for-power-bi-desktop-part-1/\n",
    "- https://powerbi.microsoft.com/en-us/blog/power-bi-premium-per-user-public-preview-now-available/\n",
    "- https://github.com/yehoshuadimarsky/python-ssas/\n",
    "- https://docs.microsoft.com/en-us/power-bi/admin/service-premium-connect-tools\n",
    "- https://docs.microsoft.com/en-us/analysis-services/tom/introduction-to-the-tabular-object-model-tom-in-analysis-services-amo?view=asallproducts-allversions\n",
    "- https://docs.microsoft.com/en-us/dotnet/api/microsoft.analysisservices.tabular.measure?view=analysisservices-dotnet\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
