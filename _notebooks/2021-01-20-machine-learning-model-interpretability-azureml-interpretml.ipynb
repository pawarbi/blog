{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Recording- Machine Learning Model Interpretability Using Azure ML\n",
    "> Recording of my presentation at Global AI Bootcamp, Singapore on Jan 16, 2021. I talked about importance of creating interpretable models and how Azure ML can be used to use to create such models without sacrificing accuracy\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [AzureML, interpretml, explainableboostingmachine, ga2m, interpretability, XAI]\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability\n",
    "\n",
    "I covered below topics in my presentation:\n",
    "\n",
    "- What is Model Interpretability?\n",
    "- Why do we need to build interpretable models?\n",
    "- Accuracy Fallacy : Accurate model does not mean correct model\n",
    "- How to create interpretable glassbox models using Explainable Boosting Machine ?\n",
    "- How Explainable Boosting Machine models work?\n",
    "- How to use interpret-ml library to obtain globally and locally important features?\n",
    "- Case Study on probing, de-bugging, comapring two different models using interpret-ml\n",
    "- Using Microsoft's 'Design Probe Thinking'\n",
    "\n",
    "\n",
    "\n",
    ">youtube: https://youtu.be/0ocVtXU8o1I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References & Resources\n",
    "\n",
    "- [How to explain models with InterpretML](https://www.youtube.com/watch?v=WwBeKMQ0-I8&t=526s)\n",
    "- [GAMUT](https://dl.acm.org/doi/fullHtml/10.1145/3290605.3300809)\n",
    "- [Using Interpret API](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/explain-model)\n",
    "- [Science Behind InterpretML](https://www.youtube.com/watch?v=g2WtL45-PFQ)\n",
    "- [FICO Challenge](https://community.fico.com/s/blog-post/a5Q2E0000001czyUAA/fico1670)\n",
    "- [Interpretability using Python](https://github.com/jphall663/interpretable_machine_learning_with_python#enhancing-transparency-in-machine-learning-models-with-python-and-xgboost---notebook)\n",
    "- [Stop explaining Black Box Models](https://arxiv.org/abs/1811.10154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
