{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Data From A File To Power BI Streaming Dataset Using Python\n",
    "> Create streaming dataset based on an existing file using Python. Super handy for POCs.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [powerbi, pandas, python, api, streaming, dataset]\n",
    "- hide: false"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Dataset\n",
    "\n",
    "It's easy to create a streaming dataset in Power BI for real-time applications. You do not need a premium capacity. To keep the blog short, I am going to assume you already know what is a streaming dataset and how it differs from import/DQ. If you are not familiar, [this documentation](https://learn.microsoft.com/en-us/power-bi/connect-data/service-real-time-streaming) will help. \n",
    "\n",
    "Imagine you are creating a POC and would like to develop the real-time dashboard, report or just want to show to your stakeholders what the solution would loook like, you will need data to stream to Power BI service. You can create Azure Event Hub, Streaming Analytics. But in this blog, I will show you how you can stream data from an existing file. I will also include a link below in the resources for a few sample datasets you can use depending on the use case. \n",
    "\n",
    "You will need a Python IDE with pandas installed.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create A Streaming dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a streaming dataset in Power BI service using the API method.\n",
    "![](https://raw.githubusercontent.com/pawarbi/blog/master/images/KP9NMM8b4g.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using this dataset for my example. Note the columns and column types from your data and create the dataset. \n",
    "![](https://raw.githubusercontent.com/pawarbi/blog/master/images/msedge_dyzzbjo5kF.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the API endpoint:\n",
    "![](https://raw.githubusercontent.com/pawarbi/blog/master/images/msedge_imlnDaqdcW.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries \n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "\n",
    "\n",
    "class StreamToPowerBI:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    Class to stream data to Power BI Streaming dataset\n",
    "    --------------------------------------------------\n",
    "    Example:\n",
    "\n",
    "     - endpoint :  API ednpoint, e.g. \"https://api.powerbi.com/beta/<ws_id>/datasets/<dataset_id>/rows?key=<___key___>\"\n",
    "     - data     :  Data in dictionary e.g. {\"id\":1, \"Value\":2.33, \"Color\":\"Red\"} \n",
    "                   Number of columns, column names and column type must match with Power BI.\n",
    "     - delay    :  Delay in seconds in sending the data to Power BI. e.g. if delay is 3, data will be sent every 3 seconds.\n",
    "                   default value is 2 seconds. To overwrite, use the wait() method\n",
    "                   \n",
    "                   \n",
    "     example:      To stream data to the specified endpoint with 5 s delay\n",
    "                   StreamToPowerBI(endpoint,data).wait(5).post_data()              \n",
    " \n",
    "    \"\"\"\n",
    "    endpoint: str\n",
    "    data: Dict\n",
    "    delay: int=2   \n",
    "        \n",
    "    def wait(self, other=None):\n",
    "        ''' Delay in seconds to stream the data '''\n",
    "        if other==None:\n",
    "            # default value is 2 seconds\n",
    "            other = 2 \n",
    "        sleep(other)    \n",
    "        return self\n",
    "    \n",
    "    def post_data(self):\n",
    "        ''' Use post method send the data to Power BI'''\n",
    "        if isinstance(self.data, dict):\n",
    "            endpoint  = self.endpoint\n",
    "            payload = [self.data]\n",
    "\n",
    "            x = requests.post(endpoint, json = payload)\n",
    "            if x.status_code==200:\n",
    "                x=x\n",
    "            else:\n",
    "                print(\"Failed ! Check endpoint, data\")\n",
    "        else:\n",
    "            print(\"Data passed is not a dictionary. It should be in the format {}\".format('{}'))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data\n",
    "\n",
    "Import the data using pandas or any other library (spark, polars etc.). Be sure to make the numeric columns type `float` otherwise json serialization will fail. I am also removing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"https://raw.githubusercontent.com/reisanar/datasets/master/eBayAuctions.csv\", \n",
    "                  index_col=None, \n",
    "                  dtype={'Category':str,\n",
    "                         'currency':str,\n",
    "                         'sellerRating':float,\n",
    "                         'Duration':float,\n",
    "                         'ClosePrice':float,\n",
    "                         'OpenPrice':float,\n",
    "                         'Competitive?':float},\n",
    "                  usecols=['Category','currency','sellerRating','Duration','ClosePrice','OpenPrice','Competitive?'])\n",
    "     ).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test \n",
    "\n",
    "Before streaming data from the whole file, let's first test using one data point. Note that in the orginal data, there is no timestamp, so I am adding the timestamp , i.e `DateTime` column, to the dictionary. In your case, you may not want to do that. comment it out if you want to stream the data as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "d = dict(df.iloc[0])\n",
    "d['DateTime']=datetime.now().isoformat()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
